{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "BASE_DIR = r\"C:\\Users\\nino.zhou\\Desktop\\my_project\\cp_newbank_mobile_behavior\"\n",
    "sys.path.insert(0, BASE_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import setting\n",
    "from config import setting\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.externals import joblib\n",
    "import datetime\n",
    "# All Includes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用论文数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Includes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Constants\n",
    "\n",
    "# Those are separate normalised input features for the neural network\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"WALKING\", \n",
    "    \"WALKING_UPSTAIRS\", \n",
    "    \"WALKING_DOWNSTAIRS\", \n",
    "    \"SITTING\", \n",
    "    \"STANDING\", \n",
    "    \"LAYING\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is now located at: C:\\Users\\nino.zhou\\Desktop\\my_project\\cp_newbank_mobile_behavior/data_model/data/UCI HAR Dataset/\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = setting.BASE_DIR + \"/data_model/data/UCI HAR Dataset/\"\n",
    "print(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128, 6), (2947, 128, 6), (7352, 1), (2947, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = \"train/\"\n",
    "TEST = \"test/\"\n",
    "\n",
    "\n",
    "# Load \"X\" (the neural network's training and testing inputs)\n",
    "\n",
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "    \n",
    "    for signal_type_path in X_signals_paths:\n",
    "        file = open(signal_type_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        X_signals.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "    \n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "X_train_signals_paths = [\n",
    "    DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "X_test_signals_paths = [\n",
    "    DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "\n",
    "X_train = load_X(X_train_signals_paths)\n",
    "X_test = load_X(X_test_signals_paths)\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]], \n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    \n",
    "    # Substract 1 to each output class for friendly 0-based indexing \n",
    "    return y_ - 1\n",
    "\n",
    "y_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\n",
    "y_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n",
    "\n",
    "# 构造和新网银行数据集一样的样本\n",
    "# 新网银行数据只有6个列，顺序分别是acc_x, acc_y, acc_z，acc_gx, acc_gy, acc_gz，因此这里要切割+顺序调整\n",
    "X_test = X_test[:, :, [6, 7, 8, 3, 4, 5]]\n",
    "X_train = X_train[:, :, [6, 7, 8, 3, 4, 5]]  \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additionnal Parameters:\n",
    "\n",
    "Here are some core parameter definitions for the training. \n",
    "\n",
    "For example, the whole neural network's structure could be summarised by enumerating those parameters and the fact that two LSTM are used one on top of another (stacked) output-to-input as hidden layers through time steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(2947, 128, 6) (2947, 1) 0.14890043 0.46668795\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "# Input Data \n",
    "\n",
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # 2947 testing series\n",
    "n_steps = len(X_train[0])  # 128 timesteps per series\n",
    "n_input = len(X_train[0][0])  # 9 input parameters per timestep\n",
    "\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 128\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLstmResNet(object):\n",
    "    def __init__(self, _X, n_classes):\n",
    "        # Function returns a tensorflow LSTM (RNN) artificial neural network from given parameters. \n",
    "        # Moreover, two LSTM cells are stacked which adds deepness to the neural network. \n",
    "        # Note, some code of this notebook is inspired from an slightly different \n",
    "        # RNN architecture used on another dataset, some of the credits goes to \n",
    "        # \"aymericdamien\" under the MIT license.\n",
    "\n",
    "        # (NOTE: This step could be greatly optimised by shaping the dataset once\n",
    "        # ReLU activation, thanks to Yu Zhao for adding this improvement here:\n",
    "        weights = tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "        biases = tf.Variable(tf.random_normal([n_hidden]))\n",
    "        _X = tf.nn.relu(tf.matmul(_X, weights) + biases)\n",
    "\n",
    "        # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "        # new shape: n_steps * (batch_size, n_hidden)\n",
    "\n",
    "\n",
    "        # bilstm + resnet残差网络\n",
    "        for i in range(2):\n",
    "            with tf.name_scope(\"bi_resnet_\" + str(i)):\n",
    "                X_shortcut = _X\n",
    "                with tf.name_scope(\"bi_lstm1\") as scope:\n",
    "                    with tf.name_scope(\"lstm_fw\"):\n",
    "                        lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                    with tf.name_scope(\"lstm_bw\"):\n",
    "                        lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                    outputs, _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, _X, dtype = tf.float32, scope=scope)\n",
    "                    outputs = tf.add(outputs[0], outputs[1])\n",
    "\n",
    "                with tf.name_scope(\"bi_lstm2\") as scope:\n",
    "                    with tf.name_scope(\"lstm_fw\"):\n",
    "                        lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                    with tf.name_scope(\"lstm_bw\"):\n",
    "                        lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                    outputs, _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, outputs, dtype = tf.float32, scope=scope)\n",
    "                    outputs = tf.concat(outputs, 2)\n",
    "\n",
    "                with tf.name_scope(\"resnet\"):\n",
    "                    outputs = tf.reshape(outputs, [-1, 2 * n_hidden])\n",
    "                    weights = tf.Variable(tf.random_normal([2 * n_hidden, n_hidden]))\n",
    "                    biases = tf.Variable(tf.random_normal([n_hidden]))\n",
    "                    outputs = tf.nn.relu(tf.matmul(outputs, weights) + biases)\n",
    "                    outputs = tf.reshape(outputs, [-1, n_steps, n_hidden]) \n",
    "                    _X = tf.add(X_shortcut, outputs)\n",
    "\n",
    "                with tf.name_scope(\"BN\") as scope:\n",
    "                    _X = tf.nn.relu(tf.layers.batch_normalization(_X, training = True))\n",
    "                    _X = tf.nn.dropout(_X, 0.7)\n",
    "\n",
    "        with tf.name_scope(\"bi_resnet_last\"):\n",
    "            X_shortcut = _X\n",
    "            with tf.name_scope(\"bi_lstm1\") as scope:\n",
    "                with tf.name_scope(\"lstm_fw\"):\n",
    "                    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                with tf.name_scope(\"lstm_bw\"):\n",
    "                    lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                outputs, _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, _X, dtype = tf.float32, scope=scope)\n",
    "                outputs = tf.add(outputs[0], outputs[1])\n",
    "\n",
    "            with tf.name_scope(\"bi_lstm2\") as scope:\n",
    "                with tf.name_scope(\"lstm_fw\"):\n",
    "                    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                with tf.name_scope(\"lstm_bw\"):\n",
    "                    lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)\n",
    "                outputs, _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, outputs, dtype = tf.float32, scope=scope)\n",
    "\n",
    "            # 最后一层只取正向的lstm输出，且不走resnet\n",
    "            _X = outputs[0]\n",
    "\n",
    "        # Get last time step's output feature for a \"many-to-one\" style classifier, \n",
    "        # as in the image describing RNNs at the top of this page\n",
    "        # Linear activation\n",
    "        lstm_last_output = _X[:, -1, :]\n",
    "        with tf.name_scope(\"pretrain_pooler\"):\n",
    "            weights = tf.Variable(tf.random_normal([n_hidden, 6], mean=1.0))\n",
    "            biases = tf.Variable(tf.random_normal([6]))\n",
    "            self.pretrain_pooled_output = tf.matmul(lstm_last_output, weights) + biases\n",
    "            \n",
    "        with tf.name_scope(\"finturn_pooler\"):\n",
    "            weights = tf.Variable(tf.random_normal([n_hidden, 19], mean=1.0))\n",
    "            biases = tf.Variable(tf.random_normal([19]))\n",
    "            self.finturn_pooled_output = tf.matmul(lstm_last_output, weights) + biases\n",
    "            \n",
    "    def get_pretrain_pooled_output(self):\n",
    "        return self.pretrain_pooled_output\n",
    "    \n",
    "    def get_finturn_pooled_output(self):\n",
    "        return self.finturn_pooled_output\n",
    "\n",
    "\n",
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index] \n",
    "\n",
    "    return batch_s\n",
    "\n",
    "\n",
    "def one_hot(y_, n_classes):\n",
    "    # Function to encode neural one-hot output labels from number indexes \n",
    "    # e.g.: \n",
    "    # one_hot(y_=[[5], [0], [3]], n_classes=6):\n",
    "    #     return [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    return np.eye(n_classes)[np.array(y_, dtype=np.int32)]  # Returns FLOATS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get serious and build the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-16-482ef6b8681f>:25: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-16-482ef6b8681f>:28: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-16-482ef6b8681f>:48: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-16-482ef6b8681f>:49: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-17-8ccbd6db0273>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Graph input/output\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "model = BiLstmResNet(x, n_classes)\n",
    "pred = model.get_pretrain_pooled_output()\n",
    "\n",
    "# Loss, optimizer and evaluation\n",
    "l2 = lambda_loss_amount * sum(\n",
    "    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n",
    ") # L2 loss prevents this overkill neural network to overfit the data\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "pred_class = tf.argmax(pred,1)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooray, now train the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce MX130, pci bus id: 0000:02:00.0, compute capability: 5.0\n",
      "\n",
      "Training iter #128:   Batch Loss = 7.508059, Accuracy = 0.125\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 7.139112949371338, Accuracy = 0.41499829292297363\n",
      "Training iter #240000:   Batch Loss = 1.090782, Accuracy = 0.8359375\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.4388999938964844, Accuracy = 0.798439085483551\n",
      "Training iter #480000:   Batch Loss = 0.348855, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.7315038442611694, Accuracy = 0.866644024848938\n",
      "Training iter #720000:   Batch Loss = 0.212389, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.6937472820281982, Accuracy = 0.8724126219749451\n",
      "Training iter #960000:   Batch Loss = 0.192828, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.6115515232086182, Accuracy = 0.8785205483436584\n",
      "Training iter #1200000:   Batch Loss = 0.454187, Accuracy = 0.875\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.5786423683166504, Accuracy = 0.870037317276001\n",
      "Training iter #1440000:   Batch Loss = 0.388765, Accuracy = 0.828125\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.5322743058204651, Accuracy = 0.9087207317352295\n",
      "Training iter #1680000:   Batch Loss = 0.157333, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.5367095470428467, Accuracy = 0.8693586587905884\n",
      "Training iter #1920000:   Batch Loss = 0.160249, Accuracy = 0.9921875\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.5242091417312622, Accuracy = 0.8842890858650208\n",
      "Training iter #2160000:   Batch Loss = 0.113192, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.44847914576530457, Accuracy = 0.9175432920455933\n",
      "Optimization Finished!\n",
      "FINAL RESULT: Batch Loss = 0.5848693251609802, Accuracy = 0.882253110408783\n"
     ]
    }
   ],
   "source": [
    "# To keep track of training's performance\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Perform Training steps with \"batch_size\" amount of example data at each loop\n",
    "step = 1\n",
    "while step * batch_size <= training_iters:\n",
    "    batch_xs = extract_batch_size(X_train, step, batch_size)\n",
    "    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size), n_classes)\n",
    "\n",
    "    # Fit training using batch data\n",
    "    _, loss, acc = sess.run(\n",
    "        [optimizer, cost, accuracy],\n",
    "        feed_dict={\n",
    "            x: batch_xs, \n",
    "            y: batch_ys\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)\n",
    "    \n",
    "    # Evaluate network only at some steps for faster training: \n",
    "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
    "        \n",
    "        # To not spam console, show training accuracy/loss in this \"if\"\n",
    "        print(\"Training iter #\" + str(step*batch_size) + \\\n",
    "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "        \n",
    "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
    "        loss, acc = sess.run(\n",
    "            [cost, accuracy], \n",
    "            feed_dict={\n",
    "                x: X_test,\n",
    "                y: one_hot(y_test, n_classes)\n",
    "            }\n",
    "        )\n",
    "        test_losses.append(loss)\n",
    "        test_accuracies.append(acc)\n",
    "        print(\"PERFORMANCE ON TEST SET: \" + \\\n",
    "              \"Batch Loss = {}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Accuracy for test data\n",
    "\n",
    "one_hot_predictions, pred_class, accuracy, final_loss = sess.run(\n",
    "    [pred, pred_class, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_test,\n",
    "        y: one_hot(y_test, n_classes),\n",
    "    }\n",
    ")\n",
    "\n",
    "test_losses.append(final_loss)\n",
    "test_accuracies.append(accuracy)\n",
    "\n",
    "print(\"FINAL RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss) + \\\n",
    "      \", Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nino.zhou\\\\Desktop\\\\my_project\\\\cp_newbank_mobile_behavior/data_model/model/bilstm_resnet_model/model.ckpt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()  # 创建保存对象\n",
    "saver.save(sess, setting.BASE_DIR + \"/data_model/model/bilstm_resnet_model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training is good, but having visual insight is even better:\n",
    "\n",
    "Okay, let's plot this simply in the notebook for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "plt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(\n",
    "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
    "    [training_iters]\n",
    ")\n",
    "plt.plot(indep_test_axis, np.array(test_losses),     \"b-\", label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"g-\", label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training iteration')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And finally, the multi-class confusion matrix and metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results: \n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "LABELS = range(19)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Outstandingly, **the final accuracy is of 91%**! And it can peak to values such as 93.25%, at some moments of luck during the training, depending on how the neural network's weights got initialized at the start of the training, randomly. \n",
    "\n",
    "This means that the neural networks is almost always able to correctly identify the movement type! Remember, the phone is attached on the waist and each series to classify has just a 128 sample window of two internal sensors (a.k.a. 2.56 seconds at 50 FPS), so it amazes me how those predictions are extremely accurate given this small window of context and raw data. I've validated and re-validated that there is no important bug, and the community used and tried this code a lot. (Note: be sure to report something in the issue tab if you find bugs, otherwise [Quora](https://www.quora.com/), [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow?sort=votes&pageSize=50), and other [StackExchange](https://stackexchange.com/sites#science) sites are the places for asking questions.)\n",
    "\n",
    "I specially did not expect such good results for guessing between the labels \"SITTING\" and \"STANDING\". Those are seemingly almost the same thing from the point of view of a device placed at waist level according to how the dataset was originally gathered. Thought, it is still possible to see a little cluster on the matrix between those classes, which drifts away just a bit from the identity. This is great.\n",
    "\n",
    "It is also possible to see that there was a slight difficulty in doing the difference between \"WALKING\", \"WALKING_UPSTAIRS\" and \"WALKING_DOWNSTAIRS\". Obviously, those activities are quite similar in terms of movements. \n",
    "\n",
    "I also tried my code without the gyroscope, using only the 3D accelerometer's 6 features (and not changing the training hyperparameters), and got an accuracy of 87%. In general, gyroscopes consumes more power than accelerometers, so it is preferable to turn them off. \n",
    "\n",
    "\n",
    "## Improvements\n",
    "\n",
    "In [another open-source repository of mine](https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs), the accuracy is pushed up to nearly 94% using a special deep LSTM architecture which combines the concepts of bidirectional RNNs, residual connections, and stacked cells. This architecture is also tested on another similar activity dataset. It resembles the nice architecture used in \"[Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/pdf/1609.08144.pdf)\", without an attention mechanism, and with just the encoder part - as a \"many to one\" architecture instead of a \"many to many\" to be adapted to the Human Activity Recognition (HAR) problem. I also worked more on the problem and came up with the [LARNN](https://github.com/guillaume-chevalier/Linear-Attention-Recurrent-Neural-Network), however it's complicated for just a little gain. Thus the current, original activity recognition project is simply better to use for its outstanding simplicity. \n",
    "\n",
    "If you want to learn more about deep learning, I have also built a list of the learning ressources for deep learning which have revealed to be the most useful to me [here](https://github.com/guillaume-chevalier/Awesome-Deep-Learning-Resources). \n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "The [dataset](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) can be found on the UCI Machine Learning Repository: \n",
    "\n",
    "> Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.\n",
    "\n",
    "The RNN image for \"many-to-one\" is taken from Karpathy's post: \n",
    "\n",
    "> Andrej Karpathy, The Unreasonable Effectiveness of Recurrent Neural Networks, 2015, \n",
    "> http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "## Citation\n",
    "\n",
    "Copyright (c) 2016 Guillaume Chevalier. To cite my code, you can point to the URL of the GitHub repository, for example: \n",
    "\n",
    "> Guillaume Chevalier, LSTMs for Human Activity Recognition, 2016, \n",
    "> https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\n",
    "\n",
    "My code is available for free and even for private usage for anyone under the [MIT License](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/blob/master/LICENSE), however I ask to cite for using the code. \n",
    "\n",
    "Here is the BibTeX citation code: \n",
    "```\n",
    "@misc{chevalier2016lstms,\n",
    "  title={LSTMs for human activity recognition},\n",
    "  author={Chevalier, Guillaume},\n",
    "  year={2016}\n",
    "}\n",
    "```\n",
    "\n",
    "## Extra links\n",
    "\n",
    "### Connect with me\n",
    "\n",
    "- [LinkedIn](https://ca.linkedin.com/in/chevalierg)\n",
    "- [Twitter](https://twitter.com/guillaume_che)\n",
    "- [GitHub](https://github.com/guillaume-chevalier/)\n",
    "- [Quora](https://www.quora.com/profile/Guillaume-Chevalier-2)\n",
    "- [YouTube](https://www.youtube.com/c/GuillaumeChevalier)\n",
    "- [Dev/Consulting](http://www.neuraxio.com/en/)\n",
    "\n",
    "### Liked this project? Did it help you? Leave a [star](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/stargazers), [fork](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/network/members) and share the love!\n",
    "\n",
    "This activity recognition project has been seen in:\n",
    "\n",
    "- [Hacker News 1st page](https://news.ycombinator.com/item?id=13049143)\n",
    "- [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow#tutorials)\n",
    "- [TensorFlow World](https://github.com/astorfi/TensorFlow-World#some-useful-tutorials)\n",
    "- And more.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's convert this notebook to a README automatically for the GitHub project's title page:\n",
    "!jupyter nbconvert --to markdown LSTM.ipynb\n",
    "!mv LSTM.md README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载新网银行比赛数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 61, 6), (2292, 61, 6), (5000,), (2292,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_feature = np.load(os.path.join(setting.BASE_DIR, \"./data_model/data/lstm_arr_x.npy\"))\n",
    "arr_y_true = np.load(os.path.join(setting.BASE_DIR, \"./data_model/data/lstm_arr_y.npy\"))\n",
    "arr_fragment_ids = np.load(os.path.join(setting.BASE_DIR, \"./data_model/data/lstm_arr_fragment_ids.npy\"))\n",
    "arr_feature = arr_feature.reshape(-1, 61, 7)\n",
    "arr_feature = arr_feature[:, :, 1:]\n",
    "\n",
    "X_train = arr_feature[:5000]\n",
    "X_test = arr_feature[5000:]\n",
    "y_train = arr_y_true[:5000]\n",
    "y_test = arr_y_true[5000:]\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(2292, 61, 6) (2292,) -0.0012841467812171117 0.983350085738804\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "# Input Data \n",
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # 2947 testing series\n",
    "n_steps = len(X_train[0])  # 128 timesteps per series\n",
    "n_input = len(X_train[0][0])  # 9 input parameters per timestep\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 19 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 128\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-482ef6b8681f>:25: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-2-482ef6b8681f>:28: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-2-482ef6b8681f>:48: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From C:\\Users\\nino.zhou\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-482ef6b8681f>:49: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-5-3d14b54d37a1>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Graph input/output\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "model = BiLstmResNet(x, n_classes)\n",
    "pred = model.get_finturn_pooled_output()  # 输出19类别维度的结果\n",
    "\n",
    "# Loss, optimizer and evaluation\n",
    "l2 = lambda_loss_amount * sum(\n",
    "    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n",
    ") # L2 loss prevents this overkill neural network to overfit the data\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "pred_class = tf.argmax(pred,1)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce MX130, pci bus id: 0000:02:00.0, compute capability: 5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.698951</td>\n",
       "      <td>-0.433187</td>\n",
       "      <td>-0.728653</td>\n",
       "      <td>0.637444</td>\n",
       "      <td>-1.668677</td>\n",
       "      <td>0.255249</td>\n",
       "      <td>0.659610</td>\n",
       "      <td>-0.847741</td>\n",
       "      <td>-1.806465</td>\n",
       "      <td>0.187687</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.057081</td>\n",
       "      <td>0.969517</td>\n",
       "      <td>0.235178</td>\n",
       "      <td>-0.007478</td>\n",
       "      <td>0.419809</td>\n",
       "      <td>-0.586455</td>\n",
       "      <td>-0.942344</td>\n",
       "      <td>0.796461</td>\n",
       "      <td>0.417467</td>\n",
       "      <td>-1.158699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.326119</td>\n",
       "      <td>1.812539</td>\n",
       "      <td>-0.905138</td>\n",
       "      <td>-0.449598</td>\n",
       "      <td>-0.121010</td>\n",
       "      <td>-0.158090</td>\n",
       "      <td>-0.864567</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-0.463028</td>\n",
       "      <td>-0.687384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463098</td>\n",
       "      <td>2.138987</td>\n",
       "      <td>-2.515596</td>\n",
       "      <td>0.206002</td>\n",
       "      <td>-0.118785</td>\n",
       "      <td>-0.698603</td>\n",
       "      <td>0.945583</td>\n",
       "      <td>1.502327</td>\n",
       "      <td>0.746327</td>\n",
       "      <td>-0.627463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.079807</td>\n",
       "      <td>-0.924794</td>\n",
       "      <td>-0.922195</td>\n",
       "      <td>0.464371</td>\n",
       "      <td>1.627714</td>\n",
       "      <td>1.197855</td>\n",
       "      <td>-0.193896</td>\n",
       "      <td>-0.736550</td>\n",
       "      <td>0.798999</td>\n",
       "      <td>0.017732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595296</td>\n",
       "      <td>0.058631</td>\n",
       "      <td>0.249398</td>\n",
       "      <td>-1.923150</td>\n",
       "      <td>-0.603278</td>\n",
       "      <td>-0.949498</td>\n",
       "      <td>0.712092</td>\n",
       "      <td>0.504264</td>\n",
       "      <td>-0.400131</td>\n",
       "      <td>0.332546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.166143</td>\n",
       "      <td>1.464615</td>\n",
       "      <td>-1.427495</td>\n",
       "      <td>-0.290825</td>\n",
       "      <td>-0.100847</td>\n",
       "      <td>-0.159492</td>\n",
       "      <td>1.452873</td>\n",
       "      <td>0.332313</td>\n",
       "      <td>3.103173</td>\n",
       "      <td>0.210181</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.028448</td>\n",
       "      <td>-0.317208</td>\n",
       "      <td>0.870311</td>\n",
       "      <td>1.355028</td>\n",
       "      <td>-1.166253</td>\n",
       "      <td>1.723183</td>\n",
       "      <td>-0.036836</td>\n",
       "      <td>-0.147719</td>\n",
       "      <td>-0.209817</td>\n",
       "      <td>-0.020769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.293911</td>\n",
       "      <td>0.104622</td>\n",
       "      <td>0.716802</td>\n",
       "      <td>0.824855</td>\n",
       "      <td>0.414387</td>\n",
       "      <td>-0.771556</td>\n",
       "      <td>1.275928</td>\n",
       "      <td>-0.275397</td>\n",
       "      <td>-1.078982</td>\n",
       "      <td>-0.719323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062931</td>\n",
       "      <td>0.157228</td>\n",
       "      <td>-1.192283</td>\n",
       "      <td>-0.826715</td>\n",
       "      <td>-0.130886</td>\n",
       "      <td>0.286609</td>\n",
       "      <td>-0.210561</td>\n",
       "      <td>-0.528799</td>\n",
       "      <td>0.288088</td>\n",
       "      <td>-0.010277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.408117</td>\n",
       "      <td>-0.336523</td>\n",
       "      <td>0.816087</td>\n",
       "      <td>1.292082</td>\n",
       "      <td>-0.471701</td>\n",
       "      <td>-0.183618</td>\n",
       "      <td>-0.325382</td>\n",
       "      <td>1.314073</td>\n",
       "      <td>-0.849194</td>\n",
       "      <td>-1.133268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416888</td>\n",
       "      <td>1.516812</td>\n",
       "      <td>0.405853</td>\n",
       "      <td>0.667030</td>\n",
       "      <td>-0.810618</td>\n",
       "      <td>2.647501</td>\n",
       "      <td>-1.371370</td>\n",
       "      <td>-0.784657</td>\n",
       "      <td>0.773238</td>\n",
       "      <td>-1.222035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.698951 -0.433187 -0.728653  0.637444 -1.668677  0.255249  0.659610   \n",
       "1 -1.326119  1.812539 -0.905138 -0.449598 -0.121010 -0.158090 -0.864567   \n",
       "2 -1.079807 -0.924794 -0.922195  0.464371  1.627714  1.197855 -0.193896   \n",
       "3 -0.166143  1.464615 -1.427495 -0.290825 -0.100847 -0.159492  1.452873   \n",
       "4  1.293911  0.104622  0.716802  0.824855  0.414387 -0.771556  1.275928   \n",
       "5 -0.408117 -0.336523  0.816087  1.292082 -0.471701 -0.183618 -0.325382   \n",
       "\n",
       "         7         8         9   ...        22        23        24        25  \\\n",
       "0 -0.847741 -1.806465  0.187687  ... -1.057081  0.969517  0.235178 -0.007478   \n",
       "1  0.391304 -0.463028 -0.687384  ...  0.463098  2.138987 -2.515596  0.206002   \n",
       "2 -0.736550  0.798999  0.017732  ... -0.595296  0.058631  0.249398 -1.923150   \n",
       "3  0.332313  3.103173  0.210181  ... -1.028448 -0.317208  0.870311  1.355028   \n",
       "4 -0.275397 -1.078982 -0.719323  ...  0.062931  0.157228 -1.192283 -0.826715   \n",
       "5  1.314073 -0.849194 -1.133268  ...  0.416888  1.516812  0.405853  0.667030   \n",
       "\n",
       "         26        27        28        29        30        31  \n",
       "0  0.419809 -0.586455 -0.942344  0.796461  0.417467 -1.158699  \n",
       "1 -0.118785 -0.698603  0.945583  1.502327  0.746327 -0.627463  \n",
       "2 -0.603278 -0.949498  0.712092  0.504264 -0.400131  0.332546  \n",
       "3 -1.166253  1.723183 -0.036836 -0.147719 -0.209817 -0.020769  \n",
       "4 -0.130886  0.286609 -0.210561 -0.528799  0.288088 -0.010277  \n",
       "5 -0.810618  2.647501 -1.371370 -0.784657  0.773238 -1.222035  \n",
       "\n",
       "[6 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = tf.get_default_graph().get_tensor_by_name(\"Variable:0\").eval()\n",
    "pd.DataFrame(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.006285</td>\n",
       "      <td>0.294867</td>\n",
       "      <td>-0.085339</td>\n",
       "      <td>4.754151e-26</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>-0.003832</td>\n",
       "      <td>0.102384</td>\n",
       "      <td>-0.120494</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>-0.183406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068499</td>\n",
       "      <td>-0.030219</td>\n",
       "      <td>0.121295</td>\n",
       "      <td>0.649131</td>\n",
       "      <td>-3.835617e-34</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>1.494776</td>\n",
       "      <td>-1.047291e-05</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>-0.860775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.090696</td>\n",
       "      <td>0.287738</td>\n",
       "      <td>-0.046503</td>\n",
       "      <td>-2.049580e-26</td>\n",
       "      <td>0.524261</td>\n",
       "      <td>-0.449429</td>\n",
       "      <td>-0.555833</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>-0.350846</td>\n",
       "      <td>0.301399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134333</td>\n",
       "      <td>-0.549066</td>\n",
       "      <td>0.104371</td>\n",
       "      <td>0.093799</td>\n",
       "      <td>2.075366e-33</td>\n",
       "      <td>-0.154621</td>\n",
       "      <td>0.599389</td>\n",
       "      <td>4.072649e-10</td>\n",
       "      <td>0.071788</td>\n",
       "      <td>0.375207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.292271</td>\n",
       "      <td>0.090162</td>\n",
       "      <td>-0.055480</td>\n",
       "      <td>-4.949238e-27</td>\n",
       "      <td>-0.313873</td>\n",
       "      <td>-0.428764</td>\n",
       "      <td>0.399681</td>\n",
       "      <td>-0.448918</td>\n",
       "      <td>-0.222726</td>\n",
       "      <td>0.289480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198499</td>\n",
       "      <td>-0.244478</td>\n",
       "      <td>0.208726</td>\n",
       "      <td>0.049530</td>\n",
       "      <td>2.541380e-34</td>\n",
       "      <td>-0.011812</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>1.853219e-10</td>\n",
       "      <td>0.131350</td>\n",
       "      <td>-0.711814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.237111</td>\n",
       "      <td>0.172313</td>\n",
       "      <td>9.283945e-25</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.301037</td>\n",
       "      <td>-0.083233</td>\n",
       "      <td>0.048220</td>\n",
       "      <td>0.532171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062085</td>\n",
       "      <td>0.240714</td>\n",
       "      <td>0.017378</td>\n",
       "      <td>-0.032796</td>\n",
       "      <td>-1.288876e-33</td>\n",
       "      <td>-0.334259</td>\n",
       "      <td>0.164963</td>\n",
       "      <td>3.389346e-05</td>\n",
       "      <td>-0.034422</td>\n",
       "      <td>0.193228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036175</td>\n",
       "      <td>-0.387973</td>\n",
       "      <td>-0.134112</td>\n",
       "      <td>-7.632570e-27</td>\n",
       "      <td>0.120555</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.195004</td>\n",
       "      <td>0.134977</td>\n",
       "      <td>-0.235438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049537</td>\n",
       "      <td>-0.072281</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>5.177031e-35</td>\n",
       "      <td>-0.270583</td>\n",
       "      <td>-0.336023</td>\n",
       "      <td>7.768295e-10</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>-0.259227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028055</td>\n",
       "      <td>0.353466</td>\n",
       "      <td>-0.227519</td>\n",
       "      <td>1.753321e-27</td>\n",
       "      <td>-0.153987</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>-0.226944</td>\n",
       "      <td>-0.125159</td>\n",
       "      <td>-0.141367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468389</td>\n",
       "      <td>0.255448</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>-0.217748</td>\n",
       "      <td>-4.307898e-34</td>\n",
       "      <td>0.181763</td>\n",
       "      <td>-0.178315</td>\n",
       "      <td>1.286192e-09</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.188053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2             3         4         5         6   \\\n",
       "0 -0.006285  0.294867 -0.085339  4.754151e-26  0.030528 -0.003832  0.102384   \n",
       "1 -0.090696  0.287738 -0.046503 -2.049580e-26  0.524261 -0.449429 -0.555833   \n",
       "2  0.292271  0.090162 -0.055480 -4.949238e-27 -0.313873 -0.428764  0.399681   \n",
       "3  0.007997  0.237111  0.172313  9.283945e-25 -0.006330  0.023712  0.301037   \n",
       "4  0.036175 -0.387973 -0.134112 -7.632570e-27  0.120555  0.035381  0.025918   \n",
       "5  0.028055  0.353466 -0.227519  1.753321e-27 -0.153987  0.023347  0.051298   \n",
       "\n",
       "         7         8         9   ...        22        23        24        25  \\\n",
       "0 -0.120494  0.015287 -0.183406  ... -0.068499 -0.030219  0.121295  0.649131   \n",
       "1  0.026392 -0.350846  0.301399  ... -0.134333 -0.549066  0.104371  0.093799   \n",
       "2 -0.448918 -0.222726  0.289480  ... -0.198499 -0.244478  0.208726  0.049530   \n",
       "3 -0.083233  0.048220  0.532171  ... -0.062085  0.240714  0.017378 -0.032796   \n",
       "4  0.195004  0.134977 -0.235438  ... -0.049537 -0.072281 -0.001138  0.012646   \n",
       "5 -0.226944 -0.125159 -0.141367  ... -0.468389  0.255448  0.012762 -0.217748   \n",
       "\n",
       "             26        27        28            29        30        31  \n",
       "0 -3.835617e-34  0.001921  1.494776 -1.047291e-05  0.012167 -0.860775  \n",
       "1  2.075366e-33 -0.154621  0.599389  4.072649e-10  0.071788  0.375207  \n",
       "2  2.541380e-34 -0.011812  0.811600  1.853219e-10  0.131350 -0.711814  \n",
       "3 -1.288876e-33 -0.334259  0.164963  3.389346e-05 -0.034422  0.193228  \n",
       "4  5.177031e-35 -0.270583 -0.336023  7.768295e-10  0.013277 -0.259227  \n",
       "5 -4.307898e-34  0.181763 -0.178315  1.286192e-09  0.025379  0.188053  \n",
       "\n",
       "[6 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = tf.get_default_graph().get_tensor_by_name(\"Variable:0\").eval()\n",
    "pd.DataFrame(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Variable',\n",
       "              <tf.Variable 'Variable:0' shape=(6, 32) dtype=float32_ref>),\n",
       "             ('Variable_1',\n",
       "              <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('batch_normalization/beta',\n",
       "              <tf.Variable 'batch_normalization/beta:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('batch_normalization/gamma',\n",
       "              <tf.Variable 'batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('batch_normalization_1/beta',\n",
       "              <tf.Variable 'batch_normalization_1/beta:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('batch_normalization_1/gamma',\n",
       "              <tf.Variable 'batch_normalization_1/gamma:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm1//bw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm1//bw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm1//bw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm1//bw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm1//fw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm1//fw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm1//fw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm1//fw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm2//bw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm2//bw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm2//bw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm2//bw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm2//fw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm2//fw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/bi_lstm2//fw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_0/bi_lstm2//fw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/resnet/Variable',\n",
       "              <tf.Variable 'bi_resnet_0/resnet/Variable:0' shape=(64, 32) dtype=float32_ref>),\n",
       "             ('bi_resnet_0/resnet/Variable_1',\n",
       "              <tf.Variable 'bi_resnet_0/resnet/Variable_1:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm1//bw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm1//bw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm1//bw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm1//bw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm1//fw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm1//fw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm1//fw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm1//fw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm2//bw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm2//bw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm2//bw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm2//bw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm2//fw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm2//fw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/bi_lstm2//fw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_1/bi_lstm2//fw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/resnet/Variable',\n",
       "              <tf.Variable 'bi_resnet_1/resnet/Variable:0' shape=(64, 32) dtype=float32_ref>),\n",
       "             ('bi_resnet_1/resnet/Variable_1',\n",
       "              <tf.Variable 'bi_resnet_1/resnet/Variable_1:0' shape=(32,) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm1//bw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm1//bw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm1//bw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm1//bw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm1//fw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm1//fw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm1//fw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm1//fw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm2//bw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm2//bw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm2//bw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm2//bw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm2//fw/basic_lstm_cell/bias',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm2//fw/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>),\n",
       "             ('bi_resnet_last/bi_lstm2//fw/basic_lstm_cell/kernel',\n",
       "              <tf.Variable 'bi_resnet_last/bi_lstm2//fw/basic_lstm_cell/kernel:0' shape=(64, 128) dtype=float32_ref>),\n",
       "             ('finturn_pooler/Variable',\n",
       "              <tf.Variable 'finturn_pooler/Variable:0' shape=(32, 19) dtype=float32_ref>),\n",
       "             ('finturn_pooler/Variable_1',\n",
       "              <tf.Variable 'finturn_pooler/Variable_1:0' shape=(19,) dtype=float32_ref>),\n",
       "             ('pretrain_pooler/Variable',\n",
       "              <tf.Variable 'pretrain_pooler/Variable:0' shape=(32, 6) dtype=float32_ref>),\n",
       "             ('pretrain_pooler/Variable_1',\n",
       "              <tf.Variable 'pretrain_pooler/Variable_1:0' shape=(6,) dtype=float32_ref>)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "tvars = tf.trainable_variables()\n",
    "name_to_variable = collections.OrderedDict()\n",
    "for var in tvars:\n",
    "    name = var.name\n",
    "    m = re.match(\"^(.*):\\\\d+$\", name)\n",
    "    if m is not None:\n",
    "        name = m.group(1)\n",
    "    name_to_variable[name] = var\n",
    "\n",
    "init_checkpoint = setting.BASE_DIR + \"/data_model/model/bilstm_resnet_model/model.ckpt\"\n",
    "init_vars = tf.train.list_variables(init_checkpoint)\n",
    "import collections\n",
    "assignment_map = collections.OrderedDict()\n",
    "for x in init_vars:\n",
    "    (name, var) = (x[0], x[1])\n",
    "    if name in name_to_variable:\n",
    "        assignment_map[name] = name_to_variable[name]\n",
    "        \n",
    "tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "sess.run(tf.global_variables_initializer())  # 再次运行global_variables_initializer()，使加载的模型参数生效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\nino.zhou\\Desktop\\my_project\\cp_newbank_mobile_behavior/data_model/model/bilstm_resnet_model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.global_variables())\n",
    "moudke_file=tf.train.latest_checkpoint(setting.BASE_DIR + \"/data_model/model/bilstm_resnet_model/\")\n",
    "saver.restore(sess, moudke_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #128:   Batch Loss = 3.046315, Accuracy = 0.046875\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.007279396057129, Accuracy = 0.16972076892852783\n",
      "Training iter #240000:   Batch Loss = 1.745227, Accuracy = 0.4375\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.6268775463104248, Accuracy = 0.49389180541038513\n",
      "Training iter #480000:   Batch Loss = 1.656731, Accuracy = 0.4453125\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5663750171661377, Accuracy = 0.5244328379631042\n",
      "Training iter #720000:   Batch Loss = 1.534860, Accuracy = 0.59375\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5320751667022705, Accuracy = 0.5641361474990845\n",
      "Training iter #960000:   Batch Loss = 1.442707, Accuracy = 0.5390625\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5075749158859253, Accuracy = 0.5763525366783142\n",
      "Training iter #1200000:   Batch Loss = 1.312786, Accuracy = 0.625\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.449526309967041, Accuracy = 0.6051483154296875\n",
      "Training iter #1440000:   Batch Loss = 1.376604, Accuracy = 0.609375\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.4791146516799927, Accuracy = 0.6230366230010986\n",
      "Optimization Finished!\n",
      "FINAL RESULT: Batch Loss = 1.438271164894104, Accuracy = 0.6265270709991455\n"
     ]
    }
   ],
   "source": [
    "# To keep track of training's performance\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Perform Training steps with \"batch_size\" amount of example data at each loop\n",
    "step = 1\n",
    "while step * batch_size <= training_iters:\n",
    "    batch_xs = extract_batch_size(X_train, step, batch_size)\n",
    "    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size), n_classes)\n",
    "\n",
    "    # Fit training using batch data\n",
    "    _, loss, acc = sess.run(\n",
    "        [optimizer, cost, accuracy],\n",
    "        feed_dict={\n",
    "            x: batch_xs, \n",
    "            y: batch_ys\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)\n",
    "    \n",
    "    # Evaluate network only at some steps for faster training: \n",
    "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
    "        \n",
    "        # To not spam console, show training accuracy/loss in this \"if\"\n",
    "        print(\"Training iter #\" + str(step*batch_size) + \\\n",
    "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "        \n",
    "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
    "        loss, acc = sess.run(\n",
    "            [cost, accuracy], \n",
    "            feed_dict={\n",
    "                x: X_test,\n",
    "                y: one_hot(y_test, n_classes)\n",
    "            }\n",
    "        )\n",
    "        test_losses.append(loss)\n",
    "        test_accuracies.append(acc)\n",
    "        print(\"PERFORMANCE ON TEST SET: \" + \\\n",
    "              \"Batch Loss = {}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Accuracy for test data\n",
    "\n",
    "one_hot_predictions, pred_class, accuracy, final_loss = sess.run(\n",
    "    [pred, pred_class, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_test,\n",
    "        y: one_hot(y_test, n_classes),\n",
    "    }\n",
    ")\n",
    "\n",
    "test_losses.append(final_loss)\n",
    "test_accuracies.append(accuracy)\n",
    "\n",
    "print(\"FINAL RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss) + \\\n",
    "      \", Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment_id</th>\n",
       "      <th>time_point</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>acc_xg</th>\n",
       "      <th>acc_yg</th>\n",
       "      <th>acc_zg</th>\n",
       "      <th>behavior_id</th>\n",
       "      <th>category_bilstm_resnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425354</th>\n",
       "      <td>7291</td>\n",
       "      <td>4561</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425355</th>\n",
       "      <td>7291</td>\n",
       "      <td>4647</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>10.7</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425356</th>\n",
       "      <td>7291</td>\n",
       "      <td>4735</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425357</th>\n",
       "      <td>7291</td>\n",
       "      <td>4830</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425358</th>\n",
       "      <td>7291</td>\n",
       "      <td>4917</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425359 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fragment_id  time_point  acc_x  acc_y  acc_z  acc_xg  acc_yg  acc_zg  \\\n",
       "0                 0          27    0.3   -0.3    0.1     0.6     4.5     8.8   \n",
       "1                 0         108    0.1   -0.0   -0.4     0.4     4.7     8.4   \n",
       "2                 0         198    0.1    0.0    0.3     0.9     4.6     9.0   \n",
       "3                 0         297    0.1   -0.1   -0.5     0.8     4.7     7.2   \n",
       "4                 0         388    0.1    0.2    0.6     0.9     4.7     8.9   \n",
       "...             ...         ...    ...    ...    ...     ...     ...     ...   \n",
       "425354         7291        4561   -0.1   -0.5   -1.7    -0.2     3.4     7.4   \n",
       "425355         7291        4647    0.7   -1.9    1.1     0.5     1.7    10.7   \n",
       "425356         7291        4735    1.3   -1.4   -0.5     1.4     2.1     8.0   \n",
       "425357         7291        4830    1.2   -1.6   -0.1     1.6     1.8     9.2   \n",
       "425358         7291        4917    1.2   -1.7    0.3     1.8     1.4     9.6   \n",
       "\n",
       "        behavior_id category_bilstm_resnet  \n",
       "0                 0                   None  \n",
       "1                 0                   None  \n",
       "2                 0                   None  \n",
       "3                 0                   None  \n",
       "4                 0                   None  \n",
       "...             ...                    ...  \n",
       "425354           18                   None  \n",
       "425355           18                   None  \n",
       "425356           18                   None  \n",
       "425357           18                   None  \n",
       "425358           18                   None  \n",
       "\n",
       "[425359 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存预测类别结果\n",
    "df_train = pd.read_csv(setting.BASE_DIR + \"\\data_model\\data\\sensor_train.csv\")\n",
    "arr_test_fragment_id = arr_fragment_ids[5000:]\n",
    "\n",
    "df_train[\"category_bilstm_resnet\"] = None\n",
    "for fragment_id, category in zip(arr_test_fragment_id, pred_class):\n",
    "    index = df_train[df_train[\"fragment_id\"] == fragment_id].index\n",
    "    df_train.loc[index, \"category_bilstm_resnet\"] = category\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造行号（因为元数据就是按顺序排列，因此不需重置顺序）\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.rename(columns={\"index\": \"id\"})\n",
    "\n",
    "df_train = df_train[[\"id\", \"fragment_id\", \"time_point\", \"behavior_id\", \"category_bilstm_resnet\"]]\n",
    "df_train.to_csv(setting.BASE_DIR + \"\\data_model\\data\\category_bilstm_resnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
