{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import resample\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "train \u003d pd.read_csv(\u0027../data/sensor_train.csv\u0027)\n",
        "test \u003d pd.read_csv(\u0027../data/sensor_test.csv\u0027)\n",
        "sub \u003d pd.read_csv(\u0027../data/提交结果示例.csv\u0027)\n",
        "y \u003d train.groupby(\u0027fragment_id\u0027)[\u0027behavior_id\u0027].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003efragment_id\u003c/th\u003e\n",
              "      \u003cth\u003etime_point\u003c/th\u003e\n",
              "      \u003cth\u003eacc_x\u003c/th\u003e\n",
              "      \u003cth\u003eacc_y\u003c/th\u003e\n",
              "      \u003cth\u003eacc_z\u003c/th\u003e\n",
              "      \u003cth\u003eacc_xg\u003c/th\u003e\n",
              "      \u003cth\u003eacc_yg\u003c/th\u003e\n",
              "      \u003cth\u003eacc_zg\u003c/th\u003e\n",
              "      \u003cth\u003ebehavior_id\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.3\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.3\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.6\u003c/td\u003e\n",
              "      \u003ctd\u003e4.5\u003c/td\u003e\n",
              "      \u003ctd\u003e8.8\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e108\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.4\u003c/td\u003e\n",
              "      \u003ctd\u003e0.4\u003c/td\u003e\n",
              "      \u003ctd\u003e4.7\u003c/td\u003e\n",
              "      \u003ctd\u003e8.4\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e198\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.3\u003c/td\u003e\n",
              "      \u003ctd\u003e0.9\u003c/td\u003e\n",
              "      \u003ctd\u003e4.6\u003c/td\u003e\n",
              "      \u003ctd\u003e9.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e3\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e297\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.5\u003c/td\u003e\n",
              "      \u003ctd\u003e0.8\u003c/td\u003e\n",
              "      \u003ctd\u003e4.7\u003c/td\u003e\n",
              "      \u003ctd\u003e7.2\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e4\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e388\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.2\u003c/td\u003e\n",
              "      \u003ctd\u003e0.6\u003c/td\u003e\n",
              "      \u003ctd\u003e0.9\u003c/td\u003e\n",
              "      \u003ctd\u003e4.7\u003c/td\u003e\n",
              "      \u003ctd\u003e8.9\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "   fragment_id  time_point  acc_x  acc_y  acc_z  acc_xg  acc_yg  acc_zg  \\\n",
              "0            0          27    0.3   -0.3    0.1     0.6     4.5     8.8   \n",
              "1            0         108    0.1   -0.0   -0.4     0.4     4.7     8.4   \n",
              "2            0         198    0.1    0.0    0.3     0.9     4.6     9.0   \n",
              "3            0         297    0.1   -0.1   -0.5     0.8     4.7     7.2   \n",
              "4            0         388    0.1    0.2    0.6     0.9     4.7     8.9   \n",
              "\n",
              "   behavior_id  \n",
              "0            0  \n",
              "1            0  \n",
              "2            0  \n",
              "3            0  \n",
              "4            0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "train[\u0027mod\u0027] \u003d (train.acc_x ** 2 + train.acc_y ** 2 + train.acc_z ** 2) ** .5\n",
        "train[\u0027modg\u0027] \u003d (train.acc_xg ** 2 + train.acc_yg ** 2 + train.acc_zg ** 2) ** .5\n",
        "test[\u0027mod\u0027] \u003d (test.acc_x ** 2 + test.acc_y ** 2 + test.acc_z ** 2) ** .5\n",
        "test[\u0027modg\u0027] \u003d (test.acc_xg ** 2 + test.acc_yg ** 2 + test.acc_zg ** 2) ** .5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7292/7292 [00:11\u003c00:00, 649.86it/s]\n",
            "100%|██████████| 7500/7500 [00:11\u003c00:00, 666.83it/s]\n"
          ]
        }
      ],
      "source": [
        "x \u003d np.zeros((7292, 60, 8))\n",
        "t \u003d np.zeros((7500, 60, 8))\n",
        "for i in tqdm(range(7292)):\n",
        "    tmp \u003d train[train.fragment_id \u003d\u003d i][:60]\n",
        "    x[i,:,:] \u003d resample(tmp.drop([\u0027fragment_id\u0027, \u0027time_point\u0027, \u0027behavior_id\u0027],\n",
        "                                    axis\u003d1), 60, np.array(tmp.time_point))[0]\n",
        "for i in tqdm(range(7500)):\n",
        "    tmp \u003d test[test.fragment_id \u003d\u003d i][:60]\n",
        "    t[i,:,:] \u003d resample(tmp.drop([\u0027fragment_id\u0027, \u0027time_point\u0027],\n",
        "                                    axis\u003d1), 60, np.array(tmp.time_point))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def Net():\n",
        "    input \u003d Input(shape\u003d(60, 8))\n",
        "    X \u003d Conv1D(filters\u003d64,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(input)\n",
        "    X \u003d Conv1D(filters\u003d128,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(X)\n",
        "    X \u003d MaxPooling1D()(X)\n",
        "    X \u003d Conv1D(filters\u003d256,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(X)\n",
        "    X \u003d Conv1D(filters\u003d512,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(X)\n",
        "    X \u003d GlobalMaxPooling1D()(X)\n",
        "    X \u003d Dropout(0.3)(X)\n",
        "    X \u003d Dense(19, activation\u003d\u0027softmax\u0027)(X)\n",
        "    return Model([input], X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "kfold \u003d StratifiedKFold(5, shuffle\u003dTrue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# proba_t \u003d np.zeros((7500, 19))\n",
        "# for fold, (xx, yy) in enumerate(kfold.split(x, y)):\n",
        "#     y_ \u003d to_categorical(y, num_classes\u003d19)\n",
        "    \n",
        "    \n",
        "#     model \u003d Net()\n",
        "#     model.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "#                   optimizer\u003dAdam(),\n",
        "#                   metrics\u003d[\u0027acc\u0027])\n",
        "    \n",
        "#     # 验证集acc不增加，自动减少学习率\n",
        "#     plateau \u003d ReduceLROnPlateau(monitor\u003d\"val_acc\",\n",
        "#                                 verbose\u003d0,\n",
        "#                                 mode\u003d\u0027max\u0027,\n",
        "#                                 factor\u003d0.1,\n",
        "#                                 patience\u003d6)\n",
        "\n",
        "#     # 防止过拟合，在验证集最优保存模型\n",
        "#     early_stopping \u003d EarlyStopping(monitor\u003d\u0027val_acc\u0027,\n",
        "#                                    verbose\u003d0,\n",
        "#                                    mode\u003d\u0027max\u0027,\n",
        "#                                    patience\u003d10)\n",
        "\n",
        "#     # 保存\n",
        "#     checkpoint \u003d ModelCheckpoint(f\u0027fold{fold}.h5\u0027,\n",
        "#                                  monitor\u003d\u0027val_acc\u0027,\n",
        "#                                  verbose\u003d0,\n",
        "#                                  mode\u003d\u0027max\u0027,\n",
        "#                                  save_best_only\u003dTrue)\n",
        "#     model.fit(x[xx], y_[xx],\n",
        "#               epochs\u003d100,\n",
        "#               batch_size\u003d512,\n",
        "#               verbose\u003d1,\n",
        "#               shuffle\u003dTrue,\n",
        "#               validation_data\u003d(x[yy], y_[yy]),\n",
        "#               callbacks\u003d[plateau, early_stopping, checkpoint])\n",
        "#     model.load_weights(f\u0027fold{fold}.h5\u0027)\n",
        "#     proba_t +\u003d model.predict(t, verbose\u003d0, batch_size\u003d1024) / 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "proba_t \u003d np.zeros((7500, 19))\n",
        "for fold, (xx, yy) in enumerate(kfold.split(x, y)):\n",
        "    y_ \u003d to_categorical(y, num_classes\u003d19)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def shuffle_index_fun(index):\n",
        "    random.shuffle(index)\n",
        "    return index.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def shuffle_data(data_x, data_y):\n",
        "    shuffle_index \u003d list(range(data_x.shape[0]))\n",
        "    r_index \u003d shuffle_index_fun(shuffle_index)\n",
        "    return data_x[r_index], data_y[r_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def mixup(batch_x, batch_y, random_max\u003d0.02):\n",
        "    shuffle_index \u003d list(range(batch_x.shape[0]))\n",
        "    r_index1 \u003d shuffle_index_fun(shuffle_index)\n",
        "    r_index2 \u003d shuffle_index_fun(shuffle_index)\n",
        "    \n",
        "    rd \u003d random.uniform(0, random_max)\n",
        "    batch_x_mixup \u003d (1-rd) * batch_x[r_index1] + rd * batch_x[r_index2]\n",
        "    batch_y_mixup \u003d (1-rd) * batch_y[r_index1] + rd * batch_y[r_index2]\n",
        "    return batch_x_mixup, batch_y_mixup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def noise(batch_x, batch_y, random_max\u003d0.02):\n",
        "    size \u003d batch_x.shape\n",
        "    \n",
        "    batch_x_noise \u003d batch_x + np.random.uniform(-random_max,random_max,size\u003dsize)\n",
        "    batch_y_noise \u003d batch_y\n",
        "    return batch_x_noise, batch_y_noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 迭代器 产生"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def generator(data_x, data_y, batch_size, dataAugment, shuffle\u003dFalse):\n",
        "    \n",
        "    # 先shuffle打乱\n",
        "    if shuffle \u003d\u003d True:\n",
        "        data_x, data_y \u003d shuffle_data(data_x, data_y)\n",
        "    \n",
        "    # 产生batch\n",
        "    while True:\n",
        "        data_num \u003d data_x.shape[0]\n",
        "        range_num \u003d data_num // batch_size + 1\n",
        "        for i in range(range_num):\n",
        "            begin_index, end_index \u003d i * batch_size, (i + 1) * batch_size\n",
        "\n",
        "            list_batch_x, list_batch_y \u003d [], []\n",
        "            if begin_index \u003c data_num:\n",
        "                batch_x, batch_y \u003d data_x[begin_index:end_index], data_y[begin_index:end_index]\n",
        "                list_batch_x.append(batch_x), list_batch_y.append(batch_y)\n",
        "\n",
        "                # 数据增强 \n",
        "                if dataAugment \u003d\u003d True:\n",
        "                    # 数据增强 mixup\n",
        "                    batch_x_mixup, batch_y_mixup \u003d mixup(batch_x, batch_y, random_max\u003d0.05)\n",
        "                    list_batch_x.append(batch_x_mixup), list_batch_y.append(batch_y_mixup)\n",
        "\n",
        "                    # 数据增强 噪声\n",
        "                    batch_x_noise, batch_y_noise \u003d noise(batch_x, batch_y, random_max\u003d0.01)\n",
        "                    list_batch_x.append(batch_x_noise), list_batch_y.append(batch_y_noise)\n",
        "\n",
        "                    # 其他\n",
        "\n",
        "                batch_x_yield, batch_y_yield \u003d np.vstack(list_batch_x), np.vstack(list_batch_y)\n",
        "                yield batch_x_yield, batch_y_yield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 保证数据一致"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 打乱"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "x[xx], y_[xx] \u003d shuffle_data(x[xx], y_[xx])\n",
        "batch_size \u003d 512\n",
        "steps_per_epoch \u003d x[xx].shape[0]//batch_size+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 数据增强"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "ge \u003d generator(x[xx], y_[xx], batch_size, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 不数据增强"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "ge_false \u003d generator(x[xx], y_[xx], batch_size, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 数据增强测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 不增强"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 16s 1s/step - loss: 2.5836 - acc: 0.1972 - val_loss: 2.1501 - val_acc: 0.3112\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1a484b2290\u003e"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(ge_false, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### 增强"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 38s 3s/step - loss: 2.6717 - acc: 0.1797 - val_loss: 2.2555 - val_acc: 0.2940\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x10aa66510\u003e"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(ge, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 自定义 loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def my_loss(y_true, y_pred, smooth_wight\u003d0.0000001, eps\u003d0.00001):\n",
        "    \n",
        "    # sigmod\n",
        "    loss \u003d (y_true - smooth_wight) * tf.math.log(y_pred + eps) + (1 - y_true - smooth_wight) * tf.math.log(1 - y_pred + eps)\n",
        "    loss \u003d -tf.reduce_mean(loss)\n",
        "    \n",
        "    # loss \u003d tf.reduce_mean(-tf.reduce_sum(y_true*tf.math.log(y_pred)))\n",
        "    # loss \u003d -tf.reduce_mean(y_true*tf.math.log(y_pred + eps))\n",
        "    # loss \u003d tf.losses.categorical_crossentropy(y_true, y_pred,label_smoothing\u003dsmooth_wight)\n",
        "    \n",
        "    return loss     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003dmy_loss,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 15s 1s/step - loss: 0.1843 - acc: 0.2225 - val_loss: 0.1634 - val_acc: 0.3372\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1a5800b8d0\u003e"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(ge_false, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 查看代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# tf.losses.categorical_crossentropy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# !cat ~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# metrics分数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def acc_combo(y, y_pred):\n",
        "    # 数值ID与行为编码的对应关系\n",
        "    mapping \u003d {0: \u0027A_0\u0027, 1: \u0027A_1\u0027, 2: \u0027A_2\u0027, 3: \u0027A_3\u0027, \n",
        "        4: \u0027D_4\u0027, 5: \u0027A_5\u0027, 6: \u0027B_1\u0027,7: \u0027B_5\u0027, \n",
        "        8: \u0027B_2\u0027, 9: \u0027B_3\u0027, 10: \u0027B_0\u0027, 11: \u0027A_6\u0027, \n",
        "        12: \u0027C_1\u0027, 13: \u0027C_3\u0027, 14: \u0027C_0\u0027, 15: \u0027B_6\u0027, \n",
        "        16: \u0027C_2\u0027, 17: \u0027C_5\u0027, 18: \u0027C_6\u0027}\n",
        "    # 将行为ID转为编码\n",
        "    code_y, code_y_pred \u003d mapping[y], mapping[y_pred]\n",
        "    if code_y \u003d\u003d code_y_pred: #编码完全相同得分1.0\n",
        "        return 1.0\n",
        "    elif code_y.split(\"_\")[0] \u003d\u003d code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n",
        "        return 1.0/7\n",
        "    elif code_y.split(\"_\")[1] \u003d\u003d code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n",
        "        return 1.0/3\n",
        "    else:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# 场景+动作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def acc_combo(y_true, y_pred):\n",
        "    try:\n",
        "        # 场景\n",
        "        map_scene \u003d tf.constant([\u0027A\u0027,\u0027A\u0027,\u0027A\u0027,\u0027A\u0027,\u0027D\u0027,\u0027A\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027A\u0027,\u0027C\u0027,\u0027C\u0027,\u0027C\u0027,\u0027B\u0027,\u0027C\u0027,\u0027C\u0027,\u0027C\u0027])\n",
        "        # 动作\n",
        "        map_action \u003d tf.constant([\u00270\u0027,\u00271\u0027,\u00272\u0027,\u00273\u0027,\u00274\u0027,\u00275\u0027,\u00271\u0027,\u00275\u0027,\u00272\u0027,\u00273\u0027,\u00270\u0027,\u00276\u0027,\u00271\u0027,\u00273\u0027,\u00270\u0027,\u00276\u0027,\u00272\u0027,\u00275\u0027,\u00276\u0027])\n",
        "\n",
        "        # 预测标签\n",
        "        # 动作+场景\n",
        "        y_true_index, y_pred_index \u003d tf.argmax(y_true,axis\u003d1), tf.argmax(y_pred,axis\u003d1)\n",
        "        # 动作\n",
        "        y_true_index_scene, y_pred_index_scene \u003d tf.nn.embedding_lookup(map_scene,y_true_index), tf.nn.embedding_lookup(map_action,y_pred_index)\n",
        "        # 场景\n",
        "        y_true_index_action, y_pred_index_action \u003d tf.nn.embedding_lookup(map_action,y_true_index), tf.nn.embedding_lookup(map_action,y_pred_index)\n",
        "\n",
        "        # 动作 1.0/7\n",
        "        acc_scene \u003d tf.cast(tf.equal(y_true_index_scene, y_pred_index_scene),tf.float16)\n",
        "        # 场景 1.0/3 \n",
        "        acc_action \u003d tf.cast(tf.equal(y_true_index_action, y_pred_index_action),tf.float16)\n",
        "        # 动作 + 场景 (1-1.0/3-1.0/7) \u003d 11/21\n",
        "        acc_classification \u003d tf.cast(tf.equal(y_true_index, y_pred_index),tf.float16)\n",
        "\n",
        "        # 得分\n",
        "        score \u003d tf.reduce_mean(1.0/7 * acc_scene + 1.0/3 * acc_action + 11/21 * acc_classification)\n",
        "    except:\n",
        "        print(y_true), print(y_pred)\n",
        "        print(y_true_index), print(y_pred_index)\n",
        "    return score "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003dmy_loss,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[acc_combo,\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 14s 1s/step - loss: 0.1928 - acc_combo: 0.2346 - acc: 0.1946 - val_loss: 0.1674 - val_acc_combo: 0.3375 - val_acc: 0.3098\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1a48d69d50\u003e"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(ge_false, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 直接优化可以吗？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003dacc_combo,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[acc_combo])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No gradients provided for any variable: [\u0027conv1d_20/kernel:0\u0027, \u0027conv1d_20/bias:0\u0027, \u0027conv1d_21/kernel:0\u0027, \u0027conv1d_21/bias:0\u0027, \u0027conv1d_22/kernel:0\u0027, \u0027conv1d_22/bias:0\u0027, \u0027conv1d_23/kernel:0\u0027, \u0027conv1d_23/bias:0\u0027, \u0027dense_5/kernel:0\u0027, \u0027dense_5/bias:0\u0027].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-35-87565b028698\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mge_false\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1297\u001b[0;31m         steps_name\u003d\u0027steps_per_epoch\u0027)\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs \u003d training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 973\u001b[0;31m           class_weight\u003dclass_weight, reset_metrics\u003dreset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs \u003d (outputs[\u0027total_loss\u0027] + outputs[\u0027output_losses\u0027] +\n\u001b[1;32m    975\u001b[0m                  outputs[\u0027metrics\u0027])\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 264\u001b[0;31m       output_loss_metrics\u003dmodel._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 311\u001b[0;31m           output_loss_metrics\u003doutput_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning(\u0027The list of trainable weights is empty. Make sure that\u0027\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \"\"\"\n\u001b[0;32m--\u003e 427\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-\u003e 1025\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1026\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     logging.warning(\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: [\u0027conv1d_20/kernel:0\u0027, \u0027conv1d_20/bias:0\u0027, \u0027conv1d_21/kernel:0\u0027, \u0027conv1d_21/bias:0\u0027, \u0027conv1d_22/kernel:0\u0027, \u0027conv1d_22/bias:0\u0027, \u0027conv1d_23/kernel:0\u0027, \u0027conv1d_23/bias:0\u0027, \u0027dense_5/kernel:0\u0027, \u0027dense_5/bias:0\u0027]."
          ]
        }
      ],
      "source": [
        "model.fit_generator(ge_false, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 测试加权"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def acc_combo_loss(y_true, y_pred, smooth_wight\u003d0.001, eps\u003d0.001):\n",
        "\n",
        "    # 场景\n",
        "    map_scene \u003d tf.constant([\u0027A\u0027,\u0027A\u0027,\u0027A\u0027,\u0027A\u0027,\u0027D\u0027,\u0027A\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027A\u0027,\u0027C\u0027,\u0027C\u0027,\u0027C\u0027,\u0027B\u0027,\u0027C\u0027,\u0027C\u0027,\u0027C\u0027])\n",
        "    # 动作\n",
        "    map_action \u003d tf.constant([\u00270\u0027,\u00271\u0027,\u00272\u0027,\u00273\u0027,\u00274\u0027,\u00275\u0027,\u00271\u0027,\u00275\u0027,\u00272\u0027,\u00273\u0027,\u00270\u0027,\u00276\u0027,\u00271\u0027,\u00273\u0027,\u00270\u0027,\u00276\u0027,\u00272\u0027,\u00275\u0027,\u00276\u0027])\n",
        "\n",
        "    # 预测标签\n",
        "    # 动作+场景\n",
        "    y_true_index, y_pred_index \u003d tf.argmax(y_true,axis\u003d1), tf.argmax(y_pred,axis\u003d1)\n",
        "    # 动作\n",
        "    y_true_index_scene, y_pred_index_scene \u003d tf.nn.embedding_lookup(map_scene,y_true_index), tf.nn.embedding_lookup(map_action,y_pred_index)\n",
        "    # 场景\n",
        "    y_true_index_action, y_pred_index_action \u003d tf.nn.embedding_lookup(map_action,y_true_index), tf.nn.embedding_lookup(map_action,y_pred_index)\n",
        "\n",
        "    # 动作 1.0/7\n",
        "    acc_scene \u003d tf.cast(tf.equal(y_true_index_scene, y_pred_index_scene),tf.float32)\n",
        "    # 场景 1.0/3 \n",
        "    acc_action \u003d tf.cast(tf.equal(y_true_index_action, y_pred_index_action),tf.float32)\n",
        "    # 动作 + 场景 (1-1.0/3-1.0/7) \u003d 11/21\n",
        "    acc_classification \u003d tf.cast(tf.equal(y_true_index, y_pred_index),tf.float32)\n",
        "\n",
        "    # 得分\n",
        "    score \u003d tf.reduce_mean(1.0/7 * acc_scene + 1.0/3 * acc_action + 11/21 * acc_classification)\n",
        "    loss \u003d (y_true - smooth_wight) * tf.math.log(y_pred + eps) + (1 - y_true - smooth_wight) * tf.math.log(1 - y_pred + eps)\n",
        "#     loss \u003d - tf.reduce_mean(loss)\n",
        "    loss \u003d - tf.reduce_sum(loss ** (1+ 0.1 * score))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def my_bias_loss(y_true, y_pred, smooth_wight\u003d0.001, eps\u003d0.001):\n",
        "\n",
        "    loss \u003d (y_true - smooth_wight) * tf.math.log(y_pred + eps)  +\\\n",
        "    (1 - y_true - smooth_wight) * tf.math.log(1 - y_pred + eps) \n",
        "    loss \u003d loss * (y_true - y_pred) ** 2\n",
        "    loss \u003d -tf.reduce_mean(loss) \n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 测试对比 score加入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003dmy_bias_loss,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[acc_combo,\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# model.fit(x[xx], y_[xx], epochs\u003d1, batch_size\u003dbatch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 14s 1s/step - loss: 0.1225 - acc_combo: 0.2374 - acc: 0.1915 - val_loss: 0.0971 - val_acc_combo: 0.3309 - val_acc: 0.2858\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1a58021790\u003e"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(ge_false, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 测试对比 不加入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model \u003d Net()\n",
        "model.compile(loss\u003dmy_loss,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[acc_combo,\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# model.fit(x[xx], y_[xx], epochs\u003d1, batch_size\u003dbatch_size,  validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 15s 1s/step - loss: 0.1851 - acc_combo: 0.2525 - acc: 0.2100 - val_loss: 0.1642 - val_acc_combo: 0.3316 - val_acc: 0.2879\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1a79cedcd0\u003e"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(ge_false, epochs\u003d1, steps_per_epoch\u003dsteps_per_epoch, validation_data\u003d(x[yy], y_[yy]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 有没有问题？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\u0027A\u0027, \u0027B\u0027, \u0027C\u0027, \u0027D\u0027}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set([\u0027A\u0027,\u0027A\u0027,\u0027A\u0027,\u0027A\u0027,\u0027D\u0027,\u0027A\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027B\u0027,\u0027A\u0027,\u0027C\u0027,\u0027C\u0027,\u0027C\u0027,\u0027B\u0027,\u0027C\u0027,\u0027C\u0027,\u0027C\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\u00270\u0027, \u00271\u0027, \u00272\u0027, \u00273\u0027, \u00274\u0027, \u00275\u0027, \u00276\u0027}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set([\u00270\u0027,\u00271\u0027,\u00272\u0027,\u00273\u0027,\u00274\u0027,\u00275\u0027,\u00271\u0027,\u00275\u0027,\u00272\u0027,\u00273\u0027,\u00270\u0027,\u00276\u0027,\u00271\u0027,\u00273\u0027,\u00270\u0027,\u00276\u0027,\u00272\u0027,\u00275\u0027,\u00276\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def Net2():\n",
        "    input \u003d Input(shape\u003d(60, 8))\n",
        "    X \u003d Conv1D(filters\u003d64,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(input)\n",
        "    X \u003d Conv1D(filters\u003d128,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(X)\n",
        "    X \u003d MaxPooling1D()(X)\n",
        "    X \u003d Conv1D(filters\u003d256,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(X)\n",
        "    X \u003d Conv1D(filters\u003d512,\n",
        "               kernel_size\u003d(3),\n",
        "               activation\u003d\u0027relu\u0027,\n",
        "               padding\u003d\u0027same\u0027)(X)\n",
        "    X \u003d GlobalMaxPooling1D()(X)\n",
        "    X \u003d Dropout(0.3)(X)\n",
        "    X_cls \u003d Dense(19, activation\u003d\u0027softmax\u0027)(X)\n",
        "    X_sence \u003d Dense(4, activation\u003d\u0027softmax\u0027)(X)\n",
        "    X_action \u003d Dense(7, activation\u003d\u0027softmax\u0027)(X)\n",
        "    \n",
        "    return Model([input], [X_cls,X_sence,X_action])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def loss_multi(y_true, y_pred, smooth_wight\u003d0.001, eps\u003d0.001):\n",
        "    \n",
        "    X_cls, X_sence, X_action \u003d y_pred[0], y_pred[1], y_pred[2]\n",
        "    y_cls, y_sence, y_action \u003d y_true[0], y_true[1], y_true[2]\n",
        "    \n",
        "    loss_cls \u003d tf.losses.categorical_crossentropy(y_cls, X_cls)\n",
        "    loss_sence \u003d tf.losses.categorical_crossentropy(y_sence, X_sence)\n",
        "    loss_action \u003d tf.losses.categorical_crossentropy(y_action, X_action)\n",
        "    \n",
        "#     return [loss_cls, loss_sence, loss_action]\n",
        "    return tf.reduce_mean(1.0/7 * loss_sence + 1.0/3 * loss_action + 11/21 * loss_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model2 \u003d Net2()\n",
        "model2.compile(loss\u003dloss_multi,\n",
        "                  optimizer\u003dAdam(),\n",
        "                  metrics\u003d[\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_9 (InputLayer)            [(None, 60, 8)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_32 (Conv1D)              (None, 60, 64)       1600        input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_33 (Conv1D)              (None, 60, 128)      24704       conv1d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1D)  (None, 30, 128)      0           conv1d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_34 (Conv1D)              (None, 30, 256)      98560       max_pooling1d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_35 (Conv1D)              (None, 30, 512)      393728      conv1d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_8 (GlobalM (None, 512)          0           conv1d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 512)          0           global_max_pooling1d_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 19)           9747        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 4)            2052        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 7)            3591        dropout_8[0][0]                  \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 533,982\n",
            "Trainable params: 533,982\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 多个loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "mapping \u003d {0: \u0027A_0\u0027, 1: \u0027A_1\u0027, 2: \u0027A_2\u0027, 3: \u0027A_3\u0027, \n",
        "        4: \u0027D_4\u0027, 5: \u0027A_5\u0027, 6: \u0027B_1\u0027,7: \u0027B_5\u0027, \n",
        "        8: \u0027B_2\u0027, 9: \u0027B_3\u0027, 10: \u0027B_0\u0027, 11: \u0027A_6\u0027, \n",
        "        12: \u0027C_1\u0027, 13: \u0027C_3\u0027, 14: \u0027C_0\u0027, 15: \u0027B_6\u0027, \n",
        "        16: \u0027C_2\u0027, 17: \u0027C_5\u0027, 18: \u0027C_6\u0027}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "mapping3 \u003d {\u0027A\u0027:0, \u0027B\u0027:1, \u0027C\u0027:2, \u0027D\u0027:2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "train \u003d pd.read_csv(\u0027../data/sensor_train.csv\u0027)\n",
        "test \u003d pd.read_csv(\u0027../data/sensor_test.csv\u0027)\n",
        "sub \u003d pd.read_csv(\u0027../data/提交结果示例.csv\u0027)\n",
        "train[\u0027sence\u0027] \u003d train[\u0027behavior_id\u0027].map(lambda x:mapping3[mapping[x].split(\u0027_\u0027)[0]])\n",
        "train[\u0027action\u0027] \u003d train[\u0027behavior_id\u0027].map(lambda x:int(mapping[x].split(\u0027_\u0027)[1]))\n",
        "y_cls \u003d train.groupby(\u0027fragment_id\u0027)[\u0027behavior_id\u0027].min()\n",
        "y_scene \u003d train.groupby(\u0027fragment_id\u0027)[\u0027sence\u0027].min()\n",
        "y_action \u003d train.groupby(\u0027fragment_id\u0027)[\u0027action\u0027].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003efragment_id\u003c/th\u003e\n",
              "      \u003cth\u003etime_point\u003c/th\u003e\n",
              "      \u003cth\u003eacc_x\u003c/th\u003e\n",
              "      \u003cth\u003eacc_y\u003c/th\u003e\n",
              "      \u003cth\u003eacc_z\u003c/th\u003e\n",
              "      \u003cth\u003eacc_xg\u003c/th\u003e\n",
              "      \u003cth\u003eacc_yg\u003c/th\u003e\n",
              "      \u003cth\u003eacc_zg\u003c/th\u003e\n",
              "      \u003cth\u003ebehavior_id\u003c/th\u003e\n",
              "      \u003cth\u003esence\u003c/th\u003e\n",
              "      \u003cth\u003eaction\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e27\u003c/td\u003e\n",
              "      \u003ctd\u003e0.3\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.3\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.6\u003c/td\u003e\n",
              "      \u003ctd\u003e4.5\u003c/td\u003e\n",
              "      \u003ctd\u003e8.8\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e108\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.4\u003c/td\u003e\n",
              "      \u003ctd\u003e0.4\u003c/td\u003e\n",
              "      \u003ctd\u003e4.7\u003c/td\u003e\n",
              "      \u003ctd\u003e8.4\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e198\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0.3\u003c/td\u003e\n",
              "      \u003ctd\u003e0.9\u003c/td\u003e\n",
              "      \u003ctd\u003e4.6\u003c/td\u003e\n",
              "      \u003ctd\u003e9.0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e3\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e297\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e-0.5\u003c/td\u003e\n",
              "      \u003ctd\u003e0.8\u003c/td\u003e\n",
              "      \u003ctd\u003e4.7\u003c/td\u003e\n",
              "      \u003ctd\u003e7.2\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e4\u003c/th\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e388\u003c/td\u003e\n",
              "      \u003ctd\u003e0.1\u003c/td\u003e\n",
              "      \u003ctd\u003e0.2\u003c/td\u003e\n",
              "      \u003ctd\u003e0.6\u003c/td\u003e\n",
              "      \u003ctd\u003e0.9\u003c/td\u003e\n",
              "      \u003ctd\u003e4.7\u003c/td\u003e\n",
              "      \u003ctd\u003e8.9\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "      \u003ctd\u003e0\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "   fragment_id  time_point  acc_x  acc_y  acc_z  acc_xg  acc_yg  acc_zg  \\\n",
              "0            0          27    0.3   -0.3    0.1     0.6     4.5     8.8   \n",
              "1            0         108    0.1   -0.0   -0.4     0.4     4.7     8.4   \n",
              "2            0         198    0.1    0.0    0.3     0.9     4.6     9.0   \n",
              "3            0         297    0.1   -0.1   -0.5     0.8     4.7     7.2   \n",
              "4            0         388    0.1    0.2    0.6     0.9     4.7     8.9   \n",
              "\n",
              "   behavior_id  sence  action  \n",
              "0            0      0       0  \n",
              "1            0      0       0  \n",
              "2            0      0       0  \n",
              "3            0      0       0  \n",
              "4            0      0       0  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "train[\u0027mod\u0027] \u003d (train.acc_x ** 2 + train.acc_y ** 2 + train.acc_z ** 2) ** .5\n",
        "train[\u0027modg\u0027] \u003d (train.acc_xg ** 2 + train.acc_yg ** 2 + train.acc_zg ** 2) ** .5\n",
        "test[\u0027mod\u0027] \u003d (test.acc_x ** 2 + test.acc_y ** 2 + test.acc_z ** 2) ** .5\n",
        "test[\u0027modg\u0027] \u003d (test.acc_xg ** 2 + test.acc_yg ** 2 + test.acc_zg ** 2) ** .5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7292/7292 [00:10\u003c00:00, 691.24it/s]\n",
            "100%|██████████| 7500/7500 [00:11\u003c00:00, 628.31it/s]\n"
          ]
        }
      ],
      "source": [
        "x \u003d np.zeros((7292, 60, 8))\n",
        "t \u003d np.zeros((7500, 60, 8))\n",
        "for i in tqdm(range(7292)):\n",
        "    tmp \u003d train[train.fragment_id \u003d\u003d i][:60]\n",
        "    x[i,:,:] \u003d resample(tmp.drop([\u0027fragment_id\u0027, \u0027time_point\u0027, \u0027behavior_id\u0027, \u0027sence\u0027, \u0027action\u0027],\n",
        "                                    axis\u003d1), 60, np.array(tmp.time_point))[0]\n",
        "for i in tqdm(range(7500)):\n",
        "    tmp \u003d test[test.fragment_id \u003d\u003d i][:60]\n",
        "    t[i,:,:] \u003d resample(tmp.drop([\u0027fragment_id\u0027, \u0027time_point\u0027],\n",
        "                                    axis\u003d1), 60, np.array(tmp.time_point))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "y_cls_ \u003d to_categorical(y_cls, num_classes\u003d19)\n",
        "y_sence_ \u003d to_categorical(y_scene, num_classes\u003d4)\n",
        "y_action_ \u003d to_categorical(y_action, num_classes\u003d7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "for fold, (xx, yy) in enumerate(kfold.split(x, y)):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 5833 samples, validate on 1459 samples\n",
            "5833/5833 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 13s 2ms/sample - loss: 5.0431 - dense_8_loss: 2.5018 - dense_9_loss: 1.0243 - dense_10_loss: 1.5131 - dense_8_acc: 0.2146 - dense_9_acc: 0.4571 - dense_10_acc: 0.4751 - val_loss: 4.8070 - val_dense_8_loss: 2.3757 - val_dense_9_loss: 1.0768 - val_dense_10_loss: 1.3940 - val_dense_8_acc: 0.1960 - val_dense_9_acc: 0.4202 - val_dense_10_acc: 0.4770\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1aaee73c90\u003e"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.fit(x[xx],[y_cls_[xx],y_sence_[xx],y_action_[xx]],\\\n",
        "           validation_data\u003d[x[yy], [y_cls_[yy],y_sence_[yy],y_action_[yy]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "###########################################################\n",
        "# 注意提交前删除\n",
        "import pandas as pd \n",
        "model_sample \u003d pd.read_csv(\"model_sample.csv\")\n",
        "verify_sample \u003d pd.read_csv(\"verify_sample.csv\")\n",
        "###########################################################\n",
        "\n",
        "###########################################################\n",
        "# 提交的代码\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "CV_NUM\u003d3\n",
        "\n",
        "###########################################################\n",
        "model_sample \u003d model_sample.fillna(-1)\n",
        "verify_sample \u003d verify_sample.fillna(-1)\n",
        "\n",
        "features_col \u003d [c for c in model_sample.columns if c not in [\u0027user_id\u0027,\u0027y\u0027]]\n",
        "X \u003d model_sample[features_col].values\n",
        "y \u003d model_sample[\u0027y\u0027].values\n",
        "X_pred \u003d verify_sample[features_col].values\n",
        "\n",
        "\n",
        "skf \u003d StratifiedKFold(n_splits\u003dCV_NUM, shuffle\u003dTrue, random_state\u003d1)\n",
        "\n",
        "params \u003d {\n",
        "\t\t\u0027task\u0027: \u0027train\u0027,\n",
        "\t\t\u0027boosting_type\u0027: \u0027gbdt\u0027,\n",
        "\t\t\u0027objective\u0027: \u0027binary\u0027,\n",
        "\t\t\u0027metric\u0027: \u0027auc\u0027,\n",
        "\t\t\u0027num_leaves\u0027: 9,\n",
        "\t\t\u0027learning_rate\u0027: 0.03,\n",
        "\t\t\u0027feature_fraction_seed\u0027: 2,\n",
        "\t\t\u0027feature_fraction\u0027: 0.9,\n",
        "\t\t\u0027bagging_fraction\u0027: 0.8,\n",
        "\t\t\u0027bagging_freq\u0027: 5,\n",
        "\t\t\u0027min_data\u0027: 20,\n",
        "\t\t\u0027min_hessian\u0027: 1,\n",
        "\t\t\u0027verbose\u0027: -1,\n",
        "\t\t}\n",
        "\n",
        "\n",
        "layer_train \u003d np.zeros((X.shape[0], CV_NUM))\n",
        "test_pred \u003d np.zeros((X_pred.shape[0], CV_NUM))\n",
        "\n",
        "for k,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "\tX_train \u003d X[train_index]\n",
        "\ty_train \u003d y[train_index]\n",
        "\tX_test \u003d X[test_index]\n",
        "\ty_test \u003d y[test_index]\n",
        "\n",
        "\t# create dataset for lightgbm\n",
        "\tlgb_train \u003d lgb.Dataset(X_train, y_train)\n",
        "\tlgb_eval \u003d lgb.Dataset(X_test, y_test, reference\u003dlgb_train)\n",
        "\n",
        "\t# train\n",
        "\tgbm \u003d lgb.train(params,\n",
        "\t\t\t\tlgb_train,\n",
        "\t\t\t\tnum_boost_round\u003d10000,\n",
        "\t\t\t\tvalid_sets\u003dlgb_eval,\n",
        "\t\t\t\tearly_stopping_rounds\u003d200)\n",
        "\n",
        "\tpred_y \u003d gbm.predict(X_test, num_iteration\u003dgbm.best_iteration)\n",
        "\tlayer_train[test_index, 1] \u003d pred_y\n",
        "\n",
        "\tpred \u003d gbm.predict(X_pred, num_iteration\u003dgbm.best_iteration)\n",
        "\ttest_pred[:, k] \u003d pred\n",
        "layer_test \u003d test_pred.mean(axis\u003d1)\n",
        "\n",
        "\n",
        "X \u003d pd.DataFrame(X)\n",
        "X[\u0027pre\u0027]\u003dlayer_train[:,1]\n",
        "X_pred \u003d pd.DataFrame(X_pred)\n",
        "X_pred[\u0027pre\u0027] \u003d layer_test\n",
        "\n",
        "X \u003d X.values\n",
        "X_pred \u003d X_pred.values\n",
        "\n",
        "for cv in range(CV_NUM):\n",
        "\tX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.33, random_state\u003dcv)\n",
        "\n",
        "# for cv,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "#\tX_train \u003d X[train_index]\n",
        "#\ty_train \u003d y[train_index]\n",
        "#\tX_test \u003d X[test_index]\n",
        "#\ty_test \u003d y[test_index]\n",
        "\t\n",
        "\t# create dataset for lightgbm\n",
        "\tlgb_train \u003d lgb.Dataset(X_train, y_train)\n",
        "\tlgb_eval \u003d lgb.Dataset(X_test, y_test, reference\u003dlgb_train)\n",
        "\n",
        "\t# specify your configurations as a dict\n",
        "\tparams \u003d {\n",
        "\t\t\t\u0027task\u0027: \u0027train\u0027,\n",
        "\t\t\t\u0027boosting_type\u0027: \u0027gbdt\u0027,\n",
        "\t\t\t\u0027objective\u0027: \u0027binary\u0027,\n",
        "\t\t\t\u0027metric\u0027: \u0027auc\u0027,\n",
        "\t\t\t\u0027num_leaves\u0027: 9,\n",
        "\t\t\t\u0027learning_rate\u0027: 0.03,\n",
        "\t\t\t\u0027feature_fraction_seed\u0027: 2,\n",
        "\t\t\t\u0027feature_fraction\u0027: 0.9,\n",
        "\t\t\t\u0027bagging_fraction\u0027: 0.8,\n",
        "\t\t\t\u0027bagging_freq\u0027: 5,\n",
        "\t\t\t\u0027min_data\u0027: 20,\n",
        "\t\t\t\u0027min_hessian\u0027: 1,\n",
        "\t\t\t\u0027verbose\u0027: -1,\n",
        "\t\t\t}\n",
        "\n",
        "\t# train\n",
        "\tgbm \u003d lgb.train(params,\n",
        "\t\t\t\tlgb_train,\n",
        "\t\t\t\tnum_boost_round\u003d10000,\n",
        "\t\t\t\tvalid_sets\u003dlgb_eval,\n",
        "\t\t\t\tearly_stopping_rounds\u003d200)\n",
        "\n",
        "\t# print(\u0027Save model...\u0027)\n",
        "\t# save model to file\n",
        "\t# gbm.save_model(\u0027model.txt\u0027)\n",
        "\n",
        "\t# print(\u0027Start predicting...\u0027)\n",
        "\t# predict\n",
        "\t# y_pred \u003d gbm.predict(X_test, num_iteration\u003dgbm.best_iteration)\n",
        "\t# eval\n",
        "\t# print(\u0027The f1 of prediction is:\u0027, f1_score(y_test, np.where(y_pred \u003e\u003d 0.225,1,0)))\n",
        "\n",
        "\tpred \u003d gbm.predict(X_pred, num_iteration\u003dgbm.best_iteration)\n",
        "\tif cv \u003d\u003d 0:\n",
        "\t\tpred_out\u003dpred\n",
        "\telse:\n",
        "\t\tpred_out+\u003dpred\n",
        "\n",
        "\n",
        "pred_out \u003d pred_out * 1.0 / CV_NUM\n",
        "pred \u003d np.where(pred_out \u003e\u003d 0.24,1,0)\n",
        "verify_sample[\u0027y_prediction\u0027] \u003d pred\n",
        "predict_result \u003d verify_sample[[\u0027user_id\u0027,\u0027y_prediction\u0027]]\n",
        "###########################################################\n",
        "\n",
        "###########################################################\n",
        "# 非官方部分，线下测试\n",
        "from sklearn.metrics import f1_score\n",
        "print(f1_score(verify_sample[\u0027y\u0027],pred))\n",
        "###########################################################\n",
        "\n",
        "###########################################################\n",
        "# 官方部分\n",
        "# f1_score \u003d score(predict_result)\n",
        "###########################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# SBBTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "###########################################################\n",
        "# 提交的代码\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "class SBBTree():\n",
        "\t\"\"\"Stacking,Bootstap,Bagging----SBBTree\"\"\"\n",
        "\t\"\"\" author：Cookly \"\"\"\n",
        "\tdef __init__(self, params, stacking_num, bagging_num, bagging_test_size, num_boost_round, early_stopping_rounds):\n",
        "\t\t\"\"\"\n",
        "\t\tInitializes the SBBTree.\n",
        "        Args:\n",
        "          params : lgb params.\n",
        "          stacking_num : k_flod stacking.\n",
        "          bagging_num : bootstrap num.\n",
        "          bagging_test_size : bootstrap sample rate.\n",
        "          num_boost_round : boost num.\n",
        "\t\t  early_stopping_rounds : early_stopping_rounds.\n",
        "        \"\"\"\n",
        "\t\tself.params \u003d params\n",
        "\t\tself.stacking_num \u003d stacking_num\n",
        "\t\tself.bagging_num \u003d bagging_num\n",
        "\t\tself.bagging_test_size \u003d bagging_test_size\n",
        "\t\tself.num_boost_round \u003d num_boost_round\n",
        "\t\tself.early_stopping_rounds \u003d early_stopping_rounds\n",
        "\n",
        "\t\tself.model \u003d lgb\n",
        "\t\tself.stacking_model \u003d []\n",
        "\t\tself.bagging_model \u003d []\n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\t\t\"\"\" fit model. \"\"\"\n",
        "\t\tif self.stacking_num \u003e 1:\n",
        "\t\t\tlayer_train \u003d np.zeros((X.shape[0], 2))\n",
        "\t\t\tself.SK \u003d StratifiedKFold(n_splits\u003dself.stacking_num, shuffle\u003dTrue, random_state\u003d1)\n",
        "\t\t\tfor k,(train_index, test_index) in enumerate(self.SK.split(X, y)):\n",
        "\t\t\t\tX_train \u003d X[train_index]\n",
        "\t\t\t\ty_train \u003d y[train_index]\n",
        "\t\t\t\tX_test \u003d X[test_index]\n",
        "\t\t\t\ty_test \u003d y[test_index]\n",
        "\n",
        "\t\t\t\tlgb_train \u003d lgb.Dataset(X_train, y_train)\n",
        "\t\t\t\tlgb_eval \u003d lgb.Dataset(X_test, y_test, reference\u003dlgb_train)\n",
        "\n",
        "\t\t\t\tgbm \u003d lgb.train(self.params,\n",
        "\t\t\t\t\t\t\tlgb_train,\n",
        "\t\t\t\t\t\t\tnum_boost_round\u003dself.num_boost_round,\n",
        "\t\t\t\t\t\t\tvalid_sets\u003dlgb_eval,\n",
        "\t\t\t\t\t\t\tearly_stopping_rounds\u003dself.early_stopping_rounds)\n",
        "\n",
        "\t\t\t\tself.stacking_model.append(gbm)\n",
        "\n",
        "\t\t\t\tpred_y \u003d gbm.predict(X_test, num_iteration\u003dgbm.best_iteration)\n",
        "\t\t\t\tlayer_train[test_index, 1] \u003d pred_y\n",
        "\n",
        "\t\t\tX \u003d np.hstack((X, layer_train[:,1].reshape((-1,1)))) \n",
        "\t\telse:\n",
        "\t\t\tpass\n",
        "\t\tfor bn in range(self.bagging_num):\n",
        "\t\t\tX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003dself.bagging_test_size, random_state\u003dbn)\n",
        "\t\n",
        "\t\t\tlgb_train \u003d lgb.Dataset(X_train, y_train)\n",
        "\t\t\tlgb_eval \u003d lgb.Dataset(X_test, y_test, reference\u003dlgb_train)\n",
        "\n",
        "\t\t\tgbm \u003d lgb.train(params,\n",
        "\t\t\t\t\t\tlgb_train,\n",
        "\t\t\t\t\t\tnum_boost_round\u003d10000,\n",
        "\t\t\t\t\t\tvalid_sets\u003dlgb_eval,\n",
        "\t\t\t\t\t\tearly_stopping_rounds\u003d200)\n",
        "\n",
        "\t\t\tself.bagging_model.append(gbm)\n",
        "\t\t\n",
        "\tdef predict(self, X_pred):\n",
        "\t\t\"\"\" predict test data. \"\"\"\n",
        "\t\tif self.stacking_num \u003e 1:\n",
        "\t\t\ttest_pred \u003d np.zeros((X_pred.shape[0], self.stacking_num))\n",
        "\t\t\tfor sn,gbm in enumerate(self.stacking_model):\n",
        "\t\t\t\tpred \u003d gbm.predict(X_pred, num_iteration\u003dgbm.best_iteration)\n",
        "\t\t\t\ttest_pred[:, sn] \u003d pred\n",
        "\t\t\tX_pred \u003d np.hstack((X_pred, test_pred.mean(axis\u003d1).reshape((-1,1))))  \n",
        "\t\telse:\n",
        "\t\t\tpass \n",
        "\t\tfor bn,gbm in enumerate(self.bagging_model):\n",
        "\t\t\tpred \u003d gbm.predict(X_pred, num_iteration\u003dgbm.best_iteration)\n",
        "\t\t\tif bn \u003d\u003d 0:\n",
        "\t\t\t\tpred_out\u003dpred\n",
        "\t\t\telse:\n",
        "\t\t\t\tpred_out+\u003dpred\n",
        "\t\treturn pred_out/self.bagging_num\n",
        "\n",
        "###########################################################################\n",
        "# test code\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import make_gaussian_quantiles\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "# X, y \u003d make_classification(n_samples\u003d1000, n_features\u003d25, n_clusters_per_class\u003d1, n_informative\u003d15, random_state\u003d1)\n",
        "X, y \u003d make_gaussian_quantiles(mean\u003dNone, cov\u003d1.0, n_samples\u003d1000, n_features\u003d50, n_classes\u003d2, shuffle\u003dTrue, random_state\u003d2)\n",
        "# data \u003d load_breast_cancer()\n",
        "# X, y \u003d data.data, data.target\n",
        "X_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.33, random_state\u003d1)\n",
        "params \u003d {\n",
        "\t\t\u0027task\u0027: \u0027train\u0027,\n",
        "\t\t\u0027boosting_type\u0027: \u0027gbdt\u0027,\n",
        "\t\t\u0027objective\u0027: \u0027binary\u0027,\n",
        "\t\t\u0027metric\u0027: \u0027auc\u0027,\n",
        "\t\t\u0027num_leaves\u0027: 9,\n",
        "\t\t\u0027learning_rate\u0027: 0.03,\n",
        "\t\t\u0027feature_fraction_seed\u0027: 2,\n",
        "\t\t\u0027feature_fraction\u0027: 0.9,\n",
        "\t\t\u0027bagging_fraction\u0027: 0.8,\n",
        "\t\t\u0027bagging_freq\u0027: 5,\n",
        "\t\t\u0027min_data\u0027: 20,\n",
        "\t\t\u0027min_hessian\u0027: 1,\n",
        "\t\t\u0027verbose\u0027: -1,\n",
        "\t\t\u0027silent\u0027: 0\n",
        "\t\t}\n",
        "# test 1\n",
        "model \u003d SBBTree(params\u003dparams, stacking_num\u003d2, bagging_num\u003d1,  bagging_test_size\u003d0.33, num_boost_round\u003d10000, early_stopping_rounds\u003d200)\n",
        "model.fit(X,y)\n",
        "X_pred \u003d X[0].reshape((1,-1))\n",
        "pred\u003dmodel.predict(X_pred)\n",
        "print(\u0027pred\u0027)\n",
        "print(pred)\n",
        "print(\u0027TEST 1 ok\u0027)\n",
        "\n",
        "\u0027\u0027\u0027\n",
        "# test 1\n",
        "model \u003d SBBTree(params, stacking_num\u003d1, bagging_num\u003d1, bagging_test_size\u003d0.33, num_boost_round\u003d10000, early_stopping_rounds\u003d200)\n",
        "model.fit(X_train,y_train)\n",
        "pred1\u003dmodel.predict(X_test)\n",
        "# test 2 \n",
        "model \u003d SBBTree(params, stacking_num\u003d1, bagging_num\u003d3, bagging_test_size\u003d0.33, num_boost_round\u003d10000, early_stopping_rounds\u003d200)\n",
        "model.fit(X_train,y_train)\n",
        "pred2\u003dmodel.predict(X_test)\n",
        "# test 3 \n",
        "model \u003d SBBTree(params, stacking_num\u003d5, bagging_num\u003d1, bagging_test_size\u003d0.33, num_boost_round\u003d10000, early_stopping_rounds\u003d200)\n",
        "model.fit(X_train,y_train)\n",
        "pred3\u003dmodel.predict(X_test)\n",
        "# test 4 \n",
        "model \u003d SBBTree(params, stacking_num\u003d5, bagging_num\u003d3, bagging_test_size\u003d0.33, num_boost_round\u003d10000, early_stopping_rounds\u003d200)\n",
        "model.fit(X_train,y_train)\n",
        "pred4\u003dmodel.predict(X_test)\n",
        "fpr, tpr, thresholds \u003d metrics.roc_curve(y_test+1, pred1, pos_label\u003d2)\n",
        "print(\u0027auc: \u0027,metrics.auc(fpr, tpr))\n",
        "fpr, tpr, thresholds \u003d metrics.roc_curve(y_test+1, pred2, pos_label\u003d2)\n",
        "print(\u0027auc: \u0027,metrics.auc(fpr, tpr))\n",
        "fpr, tpr, thresholds \u003d metrics.roc_curve(y_test+1, pred3, pos_label\u003d2)\n",
        "print(\u0027auc: \u0027,metrics.auc(fpr, tpr))\n",
        "fpr, tpr, thresholds \u003d metrics.roc_curve(y_test+1, pred4, pos_label\u003d2)\n",
        "print(\u0027auc: \u0027,metrics.auc(fpr, tpr))\n",
        "\u0027\u0027\u0027"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 深度stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "inputs \u003d tf.keras.Input(shape\u003d(60,8))\n",
        "    \n",
        "# 共享层    \n",
        "layer_cnn \u003d tf.keras.layers.Conv1D(64, 10, padding\u003d\u0027same\u0027)(inputs)\n",
        "layer_maxpool \u003d tf.keras.layers.MaxPool1D(6, padding\u003d\u0027same\u0027)(layer_cnn)\n",
        "    \n",
        "for i in [3,3,3,3,3]:\n",
        "    layer_cnn \u003d tf.keras.layers.Conv1D(64, i, padding\u003d\u0027same\u0027)(layer_maxpool)\n",
        "    layer_maxpool \u003d tf.keras.layers.MaxPool1D(2, padding\u003d\u0027same\u0027)(layer_cnn)\n",
        "\n",
        "layer_flatten \u003d tf.keras.layers.Flatten()(layer_maxpool)\n",
        "\n",
        "\n",
        "# 场景 + 动作\n",
        "layer_dense_cls \u003d tf.keras.layers.Dense(units\u003d64, activation\u003dtf.nn.relu)(layer_flatten)\n",
        "outputs_cls \u003d tf.keras.layers.Dense(units\u003d19, activation\u003dtf.nn.softmax)(layer_dense_cls)\n",
        "\n",
        "# 场景\n",
        "layer_dense_sence \u003d tf.keras.layers.Dense(units\u003d64, activation\u003dtf.nn.relu)(layer_flatten)\n",
        "outputs_sence \u003d tf.keras.layers.Dense(units\u003d4, activation\u003dtf.nn.softmax)(layer_dense_sence)\n",
        "\n",
        "# 动作\n",
        "layer_dense_action \u003d tf.keras.layers.Dense(units\u003d64, activation\u003dtf.nn.relu)(layer_flatten)\n",
        "outputs_action \u003d tf.keras.layers.Dense(units\u003d7, activation\u003dtf.nn.softmax)(layer_dense_action)\n",
        "\n",
        "\n",
        "# stacking层\n",
        "list_layer \u003d [\n",
        "              layer_flatten, \n",
        "              layer_dense_cls, \n",
        "              # outputs_cls, \n",
        "              layer_dense_sence, \n",
        "              # outputs_sence,\n",
        "              layer_dense_action,\n",
        "              # outputs_action\n",
        "             ]\n",
        "layer_stacking \u003d tf.concat(list_layer,axis\u003d-1)\n",
        "outputs_fin \u003d tf.keras.layers.Dense(units\u003d19, activation\u003dtf.nn.softmax)(layer_dense_cls)\n",
        "\n",
        "outputs \u003d [outputs_cls,outputs_sence,outputs_action,outputs_fin]\n",
        "\n",
        "model \u003d tf.keras.Model(inputs\u003dinputs, outputs\u003doutputs)\n",
        "    \n",
        "model.compile(loss\u003d\u0027categorical_crossentropy\u0027,\n",
        "              optimizer\u003dtf.keras.optimizers.Adam(),\n",
        "              metrics\u003d[\u0027acc\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 5833 samples, validate on 1459 samples\n",
            "5833/5833 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 6s 1ms/sample - loss: 6.6612 - dense_148_loss: 2.2203 - dense_150_loss: 0.8300 - dense_152_loss: 1.3592 - dense_153_loss: 2.2433 - dense_148_acc: 0.2848 - dense_150_acc: 0.6029 - dense_152_acc: 0.4879 - dense_153_acc: 0.2789 - val_loss: 5.6458 - val_dense_148_loss: 1.8662 - val_dense_150_loss: 0.6815 - val_dense_152_loss: 1.2360 - val_dense_153_loss: 1.8558 - val_dense_148_acc: 0.3715 - val_dense_150_acc: 0.6854 - val_dense_152_acc: 0.5147 - val_dense_153_acc: 0.3804\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ctensorflow.python.keras.callbacks.History at 0x1aee5abe10\u003e"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x[xx],[y_cls_[xx],y_sence_[xx],y_action_[xx],y_cls_[xx]],\n",
        "         validation_data\u003d[x[yy], [y_cls_[yy],y_sence_[yy],y_action_[yy],y_cls_[yy]]]\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}