{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nfrom scipy.signal import resample\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow as tf\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": "def one_hot(labels, num_classes):\n    labels \u003d np.squeeze(labels)\n    if labels.ndim\u003d\u003d0:\n        arr \u003d np.zeros(num_classes)\n        arr[labels]\u003d1\n        return arr\n    batch_size \u003d labels.shape[0]\n    idxs \u003d np.arange(0, batch_size, 1)\n    arr \u003d np.zeros([batch_size, num_classes])\n    arr[idxs, labels] \u003d 1\n    return arr\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": "def jitter(x, snr_db):\n    \"\"\"\n    根据信噪比添加噪声\n    :param x:\n    :param snr_db:\n    :return:\n    \"\"\"\n    # 随机选择信噪比\n    assert isinstance(snr_db, list)\n    snr_db_low \u003d snr_db[0]\n    snr_db_up \u003d snr_db[1]\n    snr_db \u003d np.random.randint(snr_db_low, snr_db_up, (1,))[0]\n\n    snr \u003d 10 ** (snr_db / 10)\n    Xp \u003d np.sum(x ** 2, axis\u003d0, keepdims\u003dTrue) / x.shape[0]  # 计算信号功率\n    Np \u003d Xp / snr  # 计算噪声功率\n    n \u003d np.random.normal(size\u003dx.shape, scale\u003dnp.sqrt(Np), loc\u003d0.0)  # 计算噪声 loc均值，scale方差\n    xn \u003d x + n\n    return xn\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": "def standardization(X):\n    # x1 \u003d X.transpose(0, 1, 3, 2)\n    x1 \u003d X\n    x2 \u003d x1.reshape(-1, x1.shape[-1])\n    mean \u003d [8.03889039e-03, -6.41381949e-02, 2.37856977e-02, 8.64949391e-01,\n            2.80964889e+00, 7.83041714e+00, 6.44853358e-01, 9.78580749e+00]\n    std \u003d [0.6120893, 0.53693888, 0.7116134, 3.22046385, 3.01195336, 2.61300056, 0.87194132, 0.68427254]\n    mu\u003dnp.array(mean)\n    sigma\u003dnp.array(std)\n    x3 \u003d ((x2 - mu) / (sigma))\n    # x4 \u003d x3.reshape(x1.shape).transpose(0, 1, 3, 2)\n    x4 \u003d x3.reshape(x1.shape)\n    return x4\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 构造训练集Dataset",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": "class XWDataset(object):\n    def __init__(self,data_path,with_label\u003dTrue,n_classes\u003d19,**kwargs):\n\n        self.data_path\u003ddata_path\n        self.with_label\u003dwith_label #测试集无标签导入\n        self.n_classes\u003dn_classes\n        #增加参数 with_nosie,\n        self.with_nosie\u003dkwargs.get(\"with_nosie\",False)\n        self.noise_SNR_db\u003dkwargs.get(\"noise_SNR_db\",[5,15])\n        if self.with_nosie:\n            print(\"添加随机噪声,SNR_db:{}\".format(self.noise_SNR_db))\n        self.load_dataset()\n\n    @property\n    def data(self):\n        if self.with_label\u003d\u003dTrue:\n            return self.X,self.Y\n        else:\n            return self.X\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, index):\n        \u0027\u0027\u0027Generate one  of data\u0027\u0027\u0027\n\n        x \u003d self.X[int(index)]\n        if self.with_label \u003d\u003d True:\n            y\u003dself.Y[int(index)]\n            y\u003done_hot(y,self.n_classes)\n            return x,y\n        else:\n            return x\n    @property\n    def dim(self):\n        return tuple(self.X.shape[1:])\n\n    def load_dataset(self):\n        df \u003d pd.read_csv(self.data_path)\n        # print(df.head())\n        df \u003d df.sort_values([\u0027fragment_id\u0027, \u0027time_point\u0027])\n        ###特征提取\n        df[\u0027mod\u0027] \u003d (df.acc_x ** 2 + df.acc_y ** 2 + df.acc_z ** 2) ** .5\n        df[\u0027modg\u0027] \u003d (df.acc_xg ** 2 + df.acc_yg ** 2 + df.acc_zg ** 2) ** .5\n        ###数据读取\n\n        num \u003d np.unique(df[\"fragment_id\"]).shape[0]\n        X_shape \u003d (num,1, 60, 8)\n        X \u003d np.zeros(X_shape)\n        for i in tqdm(range(X_shape[0])):\n            tmp \u003d df[df.fragment_id \u003d\u003d i][:60]\n            if self.with_label:\n                arr \u003d resample(tmp.drop([\u0027fragment_id\u0027, \u0027time_point\u0027, \u0027behavior_id\u0027],\n                                        axis\u003d1), 60, np.array(tmp.time_point))[0]\n                X[i, 0, :, :] \u003d arr\n            else:\n                arr \u003d resample(tmp.drop([\u0027fragment_id\u0027, \u0027time_point\u0027,],\n                                        axis\u003d1), 60, np.array(tmp.time_point))[0]\n                X[i, 0, :, :] \u003d arr\n        ###############################################\n        if self.with_label:\n            #标准化\n            X\u003dstandardization(X)\n            Y \u003d np.array(df.groupby(\"fragment_id\")[\"behavior_id\"].min())\n            if self.with_nosie:\n                X1 \u003d jitter(X, self.noise_SNR_db)\n                X \u003d np.concatenate([X, X1], axis\u003d0)\n                Y \u003d np.concatenate([Y, Y], axis\u003d0)\n            self.X ,self.Y\u003dX,Y\n        else:\n            # 标准化\n            X \u003d standardization(X)\n            self.X\u003dX\n        self.fragment_ids \u003d df.groupby(\"fragment_id\")[\"fragment_id\"].min()\n        self.time_points \u003d df.groupby(\"fragment_id\")[\"time_point\"]\n        self.indexes \u003d np.arange(self.X.shape[0])\n\n    def stratifiedKFold(self,fold\u003d5):\n        kfold \u003d StratifiedKFold(fold, shuffle\u003dTrue)\n        self.X_copy,self.Y_copy\u003dself.X.copy(),self.Y.copy()\n        self.train_valid_idxs\u003d[ (train_idx,valid_idx) for train_idx,valid_idx in kfold.split(self.X_copy,self.Y_copy) ]\n\n    def get_valid_data(self,index):\n        \"\"\"\n        :param index:\n        :return:  重新划分训练集和验证集 , 并返回验证集数据\n        \"\"\"\n        train_idx,valid_idx\u003d self.train_valid_idxs[index]\n        X,Y\u003d self.X_copy[train_idx],self.Y_copy[train_idx]\n        self.X, self.Y\u003dX,Y\n        self.valid_X,self.valid_Y\u003dself.X_copy[valid_idx],self.Y_copy[valid_idx]\n        return self.valid_X,self.valid_Y\n    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7292 [00:00\u003c?, ?it/s]",
            "\r  0%|          | 15/7292 [00:00\u003c00:49, 147.75it/s]",
            "\r  1%|          | 60/7292 [00:00\u003c00:39, 185.03it/s]",
            "\r  1%|▏         | 94/7292 [00:00\u003c00:33, 213.94it/s]",
            "\r  2%|▏         | 129/7292 [00:00\u003c00:29, 241.68it/s]",
            "\r  2%|▏         | 155/7292 [00:00\u003c00:29, 244.39it/s]",
            "\r  3%|▎         | 191/7292 [00:00\u003c00:26, 268.63it/s]",
            "\r  3%|▎         | 225/7292 [00:00\u003c00:24, 285.94it/s]",
            "\r  4%|▎         | 264/7292 [00:00\u003c00:22, 309.58it/s]",
            "\r  4%|▍         | 297/7292 [00:00\u003c00:22, 307.52it/s]",
            "\r  5%|▍         | 329/7292 [00:01\u003c00:22, 310.10it/s]",
            "\r  5%|▍         | 364/7292 [00:01\u003c00:21, 319.30it/s]",
            "\r  5%|▌         | 398/7292 [00:01\u003c00:21, 322.84it/s]",
            "\r  6%|▌         | 438/7292 [00:01\u003c00:20, 341.94it/s]",
            "\r  6%|▋         | 473/7292 [00:01\u003c00:20, 331.75it/s]",
            "\r  7%|▋         | 509/7292 [00:01\u003c00:20, 335.03it/s]",
            "\r  7%|▋         | 543/7292 [00:01\u003c00:20, 334.51it/s]",
            "\r  8%|▊         | 578/7292 [00:01\u003c00:19, 337.06it/s]",
            "\r  8%|▊         | 612/7292 [00:01\u003c00:21, 307.67it/s]",
            "\r  9%|▉         | 647/7292 [00:01\u003c00:20, 319.23it/s]",
            "\r  9%|▉         | 684/7292 [00:02\u003c00:19, 332.94it/s]",
            "\r 10%|▉         | 721/7292 [00:02\u003c00:19, 341.35it/s]",
            "\r 10%|█         | 756/7292 [00:02\u003c00:19, 328.97it/s]",
            "\r 11%|█         | 790/7292 [00:02\u003c00:19, 328.37it/s]",
            "\r 11%|█▏        | 824/7292 [00:02\u003c00:19, 326.98it/s]",
            "\r 12%|█▏        | 862/7292 [00:02\u003c00:18, 341.26it/s]",
            "\r 12%|█▏        | 897/7292 [00:02\u003c00:18, 342.84it/s]",
            "\r 13%|█▎        | 932/7292 [00:02\u003c00:19, 330.31it/s]",
            "\r 13%|█▎        | 967/7292 [00:02\u003c00:18, 335.95it/s]",
            "\r 14%|█▍        | 1003/7292 [00:03\u003c00:18, 342.82it/s]",
            "\r 14%|█▍        | 1042/7292 [00:03\u003c00:17, 355.72it/s]",
            "\r 15%|█▍        | 1078/7292 [00:03\u003c00:24, 253.41it/s]",
            "\r 15%|█▌        | 1108/7292 [00:03\u003c00:23, 259.58it/s]",
            "\r 16%|█▌        | 1145/7292 [00:03\u003c00:21, 283.80it/s]",
            "\r 16%|█▌        | 1182/7292 [00:03\u003c00:20, 301.39it/s]",
            "\r 17%|█▋        | 1215/7292 [00:03\u003c00:19, 306.82it/s]",
            "\r 17%|█▋        | 1248/7292 [00:03\u003c00:19, 304.74it/s]",
            "\r 18%|█▊        | 1282/7292 [00:03\u003c00:19, 311.91it/s]",
            "\r 18%|█▊        | 1319/7292 [00:04\u003c00:18, 325.83it/s]",
            "\r 19%|█▊        | 1357/7292 [00:04\u003c00:17, 338.57it/s]",
            "\r 19%|█▉        | 1395/7292 [00:04\u003c00:16, 347.16it/s]",
            "\r 20%|█▉        | 1431/7292 [00:04\u003c00:17, 330.61it/s]",
            "\r 20%|██        | 1469/7292 [00:04\u003c00:16, 342.92it/s]",
            "\r 21%|██        | 1505/7292 [00:04\u003c00:16, 343.90it/s]",
            "\r 21%|██        | 1542/7292 [00:04\u003c00:16, 351.27it/s]",
            "\r 22%|██▏       | 1578/7292 [00:04\u003c00:16, 352.55it/s]",
            "\r 22%|██▏       | 1614/7292 [00:04\u003c00:16, 334.10it/s]",
            "\r 23%|██▎       | 1650/7292 [00:05\u003c00:16, 339.50it/s]",
            "\r 23%|██▎       | 1688/7292 [00:05\u003c00:16, 349.73it/s]",
            "\r 24%|██▎       | 1728/7292 [00:05\u003c00:15, 358.53it/s]",
            "\r 24%|██▍       | 1765/7292 [00:05\u003c00:15, 345.68it/s]",
            "\r 25%|██▍       | 1804/7292 [00:05\u003c00:15, 357.88it/s]",
            "\r 25%|██▌       | 1841/7292 [00:05\u003c00:19, 285.35it/s]",
            "\r 26%|██▌       | 1873/7292 [00:05\u003c00:18, 286.95it/s]",
            "\r 26%|██▌       | 1909/7292 [00:05\u003c00:17, 304.39it/s]",
            "\r 27%|██▋       | 1943/7292 [00:05\u003c00:17, 306.61it/s]",
            "\r 27%|██▋       | 1976/7292 [00:06\u003c00:17, 312.33it/s]",
            "\r 28%|██▊       | 2014/7292 [00:06\u003c00:16, 328.33it/s]",
            "\r 28%|██▊       | 2053/7292 [00:06\u003c00:15, 344.68it/s]",
            "\r 29%|██▊       | 2089/7292 [00:06\u003c00:15, 340.25it/s]",
            "\r 29%|██▉       | 2127/7292 [00:06\u003c00:14, 350.30it/s]",
            "\r 30%|██▉       | 2165/7292 [00:06\u003c00:14, 354.69it/s]",
            "\r 30%|███       | 2201/7292 [00:06\u003c00:14, 354.76it/s]",
            "\r 31%|███       | 2238/7292 [00:06\u003c00:14, 358.17it/s]",
            "\r 31%|███       | 2274/7292 [00:06\u003c00:16, 301.72it/s]",
            "\r 32%|███▏      | 2306/7292 [00:07\u003c00:17, 286.73it/s]",
            "\r 32%|███▏      | 2340/7292 [00:07\u003c00:16, 299.26it/s]",
            "\r 33%|███▎      | 2371/7292 [00:07\u003c00:18, 262.44it/s]",
            "\r 33%|███▎      | 2401/7292 [00:07\u003c00:18, 271.20it/s]",
            "\r 33%|███▎      | 2432/7292 [00:07\u003c00:17, 281.01it/s]",
            "\r 34%|███▍      | 2472/7292 [00:07\u003c00:15, 308.53it/s]",
            "\r 34%|███▍      | 2505/7292 [00:07\u003c00:15, 302.55it/s]",
            "\r 35%|███▍      | 2546/7292 [00:07\u003c00:14, 326.80it/s]",
            "\r 35%|███▌      | 2586/7292 [00:07\u003c00:13, 344.88it/s]",
            "\r 36%|███▌      | 2622/7292 [00:08\u003c00:16, 287.39it/s]",
            "\r 36%|███▋      | 2657/7292 [00:08\u003c00:15, 302.89it/s]",
            "\r 37%|███▋      | 2701/7292 [00:08\u003c00:13, 332.61it/s]",
            "\r 38%|███▊      | 2745/7292 [00:08\u003c00:12, 357.15it/s]",
            "\r 38%|███▊      | 2783/7292 [00:08\u003c00:14, 301.40it/s]",
            "\r 39%|███▊      | 2817/7292 [00:08\u003c00:14, 304.48it/s]",
            "\r 39%|███▉      | 2855/7292 [00:08\u003c00:13, 322.14it/s]",
            "\r 40%|███▉      | 2897/7292 [00:08\u003c00:12, 343.80it/s]",
            "\r 40%|████      | 2941/7292 [00:09\u003c00:11, 367.92it/s]",
            "\r 41%|████      | 2988/7292 [00:09\u003c00:10, 391.61it/s]",
            "\r 42%|████▏     | 3031/7292 [00:09\u003c00:10, 400.14it/s]",
            "\r 42%|████▏     | 3073/7292 [00:09\u003c00:10, 383.64it/s]",
            "\r 43%|████▎     | 3116/7292 [00:09\u003c00:10, 394.28it/s]",
            "\r 43%|████▎     | 3157/7292 [00:09\u003c00:10, 377.91it/s]",
            "\r 44%|████▍     | 3196/7292 [00:09\u003c00:10, 375.79it/s]",
            "\r 44%|████▍     | 3236/7292 [00:09\u003c00:10, 381.64it/s]",
            "\r 45%|████▍     | 3280/7292 [00:09\u003c00:10, 388.00it/s]",
            "\r 46%|████▌     | 3320/7292 [00:09\u003c00:10, 386.98it/s]",
            "\r 46%|████▌     | 3360/7292 [00:10\u003c00:10, 390.78it/s]",
            "\r 47%|████▋     | 3400/7292 [00:10\u003c00:10, 385.54it/s]",
            "\r 47%|████▋     | 3439/7292 [00:10\u003c00:10, 376.77it/s]",
            "\r 48%|████▊     | 3483/7292 [00:10\u003c00:09, 393.74it/s]",
            "\r 48%|████▊     | 3525/7292 [00:10\u003c00:09, 399.00it/s]",
            "\r 49%|████▉     | 3566/7292 [00:10\u003c00:11, 312.19it/s]",
            "\r 49%|████▉     | 3609/7292 [00:10\u003c00:10, 340.11it/s]",
            "\r 50%|█████     | 3652/7292 [00:10\u003c00:10, 362.38it/s]",
            "\r 51%|█████     | 3692/7292 [00:11\u003c00:09, 371.84it/s]",
            "\r 51%|█████     | 3734/7292 [00:11\u003c00:09, 382.98it/s]",
            "\r 52%|█████▏    | 3774/7292 [00:11\u003c00:09, 373.75it/s]",
            "\r 52%|█████▏    | 3813/7292 [00:11\u003c00:11, 314.22it/s]",
            "\r 53%|█████▎    | 3847/7292 [00:11\u003c00:11, 307.57it/s]",
            "\r 53%|█████▎    | 3880/7292 [00:11\u003c00:10, 313.07it/s]",
            "\r 54%|█████▎    | 3913/7292 [00:11\u003c00:11, 294.84it/s]",
            "\r 54%|█████▍    | 3944/7292 [00:11\u003c00:11, 297.51it/s]",
            "\r 55%|█████▍    | 3975/7292 [00:11\u003c00:11, 276.54it/s]",
            "\r 55%|█████▍    | 4008/7292 [00:12\u003c00:11, 289.14it/s]",
            "\r 55%|█████▌    | 4047/7292 [00:12\u003c00:10, 313.45it/s]",
            "\r 56%|█████▌    | 4082/7292 [00:12\u003c00:09, 323.34it/s]",
            "\r 56%|█████▋    | 4116/7292 [00:12\u003c00:09, 323.48it/s]",
            "\r 57%|█████▋    | 4158/7292 [00:12\u003c00:09, 347.38it/s]",
            "\r 58%|█████▊    | 4194/7292 [00:12\u003c00:09, 318.48it/s]",
            "\r 58%|█████▊    | 4227/7292 [00:12\u003c00:10, 295.08it/s]",
            "\r 58%|█████▊    | 4258/7292 [00:12\u003c00:10, 290.97it/s]",
            "\r 59%|█████▉    | 4301/7292 [00:12\u003c00:09, 321.35it/s]",
            "\r 60%|█████▉    | 4346/7292 [00:13\u003c00:08, 350.68it/s]",
            "\r 60%|██████    | 4389/7292 [00:13\u003c00:07, 371.21it/s]",
            "\r 61%|██████    | 4428/7292 [00:13\u003c00:07, 366.06it/s]",
            "\r 61%|██████▏   | 4469/7292 [00:13\u003c00:07, 377.18it/s]",
            "\r 62%|██████▏   | 4508/7292 [00:13\u003c00:07, 373.26it/s]",
            "\r 62%|██████▏   | 4546/7292 [00:13\u003c00:07, 357.26it/s]",
            "\r 63%|██████▎   | 4583/7292 [00:13\u003c00:07, 340.55it/s]",
            "\r 63%|██████▎   | 4618/7292 [00:13\u003c00:07, 343.33it/s]",
            "\r 64%|██████▍   | 4658/7292 [00:13\u003c00:07, 357.61it/s]",
            "\r 64%|██████▍   | 4696/7292 [00:14\u003c00:07, 363.00it/s]",
            "\r 65%|██████▍   | 4733/7292 [00:14\u003c00:08, 313.16it/s]",
            "\r 65%|██████▌   | 4766/7292 [00:14\u003c00:08, 312.61it/s]",
            "\r 66%|██████▌   | 4801/7292 [00:14\u003c00:07, 316.82it/s]",
            "\r 66%|██████▋   | 4834/7292 [00:14\u003c00:08, 284.21it/s]",
            "\r 67%|██████▋   | 4864/7292 [00:14\u003c00:08, 276.01it/s]",
            "\r 67%|██████▋   | 4899/7292 [00:14\u003c00:08, 292.49it/s]",
            "\r 68%|██████▊   | 4931/7292 [00:14\u003c00:07, 297.71it/s]",
            "\r 68%|██████▊   | 4965/7292 [00:14\u003c00:07, 306.75it/s]",
            "\r 69%|██████▊   | 5002/7292 [00:15\u003c00:07, 323.33it/s]",
            "\r 69%|██████▉   | 5037/7292 [00:15\u003c00:06, 330.87it/s]",
            "\r 70%|██████▉   | 5071/7292 [00:15\u003c00:07, 282.80it/s]",
            "\r 70%|███████   | 5105/7292 [00:15\u003c00:07, 297.06it/s]",
            "\r 70%|███████   | 5140/7292 [00:15\u003c00:06, 311.18it/s]",
            "\r 71%|███████   | 5173/7292 [00:15\u003c00:06, 312.97it/s]",
            "\r 72%|███████▏  | 5215/7292 [00:15\u003c00:06, 338.06it/s]",
            "\r 72%|███████▏  | 5261/7292 [00:15\u003c00:05, 365.51it/s]",
            "\r 73%|███████▎  | 5306/7292 [00:15\u003c00:05, 386.34it/s]",
            "\r 73%|███████▎  | 5346/7292 [00:16\u003c00:05, 327.95it/s]",
            "\r 74%|███████▍  | 5383/7292 [00:16\u003c00:05, 337.67it/s]",
            "\r 74%|███████▍  | 5420/7292 [00:16\u003c00:05, 346.76it/s]",
            "\r 75%|███████▍  | 5461/7292 [00:16\u003c00:05, 363.46it/s]",
            "\r 75%|███████▌  | 5499/7292 [00:16\u003c00:05, 356.86it/s]",
            "\r 76%|███████▌  | 5536/7292 [00:16\u003c00:04, 354.41it/s]",
            "\r 76%|███████▋  | 5573/7292 [00:16\u003c00:04, 348.76it/s]",
            "\r 77%|███████▋  | 5609/7292 [00:16\u003c00:05, 329.54it/s]",
            "\r 77%|███████▋  | 5644/7292 [00:16\u003c00:04, 332.55it/s]",
            "\r 78%|███████▊  | 5678/7292 [00:17\u003c00:05, 315.95it/s]",
            "\r 78%|███████▊  | 5711/7292 [00:17\u003c00:04, 320.04it/s]",
            "\r 79%|███████▉  | 5744/7292 [00:17\u003c00:04, 321.03it/s]",
            "\r 79%|███████▉  | 5779/7292 [00:17\u003c00:04, 329.20it/s]",
            "\r 80%|███████▉  | 5813/7292 [00:17\u003c00:04, 319.28it/s]",
            "\r 80%|████████  | 5849/7292 [00:17\u003c00:04, 329.58it/s]",
            "\r 81%|████████  | 5883/7292 [00:17\u003c00:04, 321.33it/s]",
            "\r 81%|████████  | 5919/7292 [00:17\u003c00:04, 330.20it/s]",
            "\r 82%|████████▏ | 5959/7292 [00:17\u003c00:03, 346.26it/s]",
            "\r 82%|████████▏ | 5999/7292 [00:18\u003c00:03, 359.70it/s]",
            "\r 83%|████████▎ | 6041/7292 [00:18\u003c00:03, 375.87it/s]",
            "\r 83%|████████▎ | 6081/7292 [00:18\u003c00:03, 380.62it/s]",
            "\r 84%|████████▍ | 6122/7292 [00:18\u003c00:03, 387.87it/s]",
            "\r 85%|████████▍ | 6162/7292 [00:18\u003c00:02, 377.01it/s]",
            "\r 85%|████████▌ | 6200/7292 [00:18\u003c00:03, 358.66it/s]",
            "\r 86%|████████▌ | 6237/7292 [00:18\u003c00:02, 354.70it/s]",
            "\r 86%|████████▌ | 6279/7292 [00:18\u003c00:02, 371.07it/s]",
            "\r 87%|████████▋ | 6317/7292 [00:18\u003c00:02, 361.43it/s]",
            "\r 87%|████████▋ | 6355/7292 [00:18\u003c00:02, 362.52it/s]",
            "\r 88%|████████▊ | 6396/7292 [00:19\u003c00:02, 373.52it/s]",
            "\r 88%|████████▊ | 6435/7292 [00:19\u003c00:02, 378.30it/s]",
            "\r 89%|████████▉ | 6479/7292 [00:19\u003c00:02, 393.87it/s]",
            "\r 89%|████████▉ | 6519/7292 [00:19\u003c00:02, 344.56it/s]",
            "\r 90%|████████▉ | 6559/7292 [00:19\u003c00:02, 358.52it/s]",
            "\r 91%|█████████ | 6603/7292 [00:19\u003c00:01, 378.64it/s]",
            "\r 91%|█████████ | 6647/7292 [00:19\u003c00:01, 394.11it/s]",
            "\r 92%|█████████▏| 6689/7292 [00:19\u003c00:01, 400.39it/s]",
            "\r 92%|█████████▏| 6735/7292 [00:19\u003c00:01, 415.44it/s]",
            "\r 93%|█████████▎| 6779/7292 [00:20\u003c00:01, 420.12it/s]",
            "\r 94%|█████████▎| 6822/7292 [00:20\u003c00:01, 420.56it/s]",
            "\r 94%|█████████▍| 6870/7292 [00:20\u003c00:00, 436.76it/s]",
            "\r 95%|█████████▍| 6916/7292 [00:20\u003c00:00, 442.23it/s]",
            "\r 95%|█████████▌| 6961/7292 [00:20\u003c00:00, 443.19it/s]",
            "\r 96%|█████████▌| 7006/7292 [00:20\u003c00:00, 442.58it/s]",
            "\r 97%|█████████▋| 7051/7292 [00:20\u003c00:00, 443.49it/s]",
            "\r 97%|█████████▋| 7096/7292 [00:20\u003c00:00, 441.50it/s]",
            "\r 98%|█████████▊| 7144/7292 [00:20\u003c00:00, 451.08it/s]",
            "\r 99%|█████████▊| 7190/7292 [00:20\u003c00:00, 447.10it/s]",
            "\r 99%|█████████▉| 7235/7292 [00:21\u003c00:00, 440.09it/s]",
            "\r100%|█████████▉| 7281/7292 [00:21\u003c00:00, 443.30it/s]",
            "\r100%|██████████| 7292/7292 [00:21\u003c00:00, 344.45it/s]",
            "\n",
            "\r  0%|          | 0/7500 [00:00\u003c?, ?it/s]",
            "\r  0%|          | 21/7500 [00:00\u003c00:36, 205.88it/s]",
            "\r  1%|          | 58/7500 [00:00\u003c00:31, 237.03it/s]",
            "\r  1%|▏         | 103/7500 [00:00\u003c00:26, 275.74it/s]",
            "\r  2%|▏         | 133/7500 [00:00\u003c00:26, 281.01it/s]",
            "\r  2%|▏         | 174/7500 [00:00\u003c00:23, 310.29it/s]",
            "\r  3%|▎         | 222/7500 [00:00\u003c00:21, 346.35it/s]",
            "\r  4%|▎         | 269/7500 [00:00\u003c00:19, 375.13it/s]",
            "\r  4%|▍         | 317/7500 [00:00\u003c00:17, 401.44it/s]",
            "\r  5%|▍         | 365/7500 [00:00\u003c00:16, 419.95it/s]",
            "\r  5%|▌         | 410/7500 [00:01\u003c00:16, 426.12it/s]",
            "\r  6%|▌         | 455/7500 [00:01\u003c00:16, 433.00it/s]",
            "\r  7%|▋         | 499/7500 [00:01\u003c00:16, 427.49it/s]",
            "\r  7%|▋         | 543/7500 [00:01\u003c00:17, 407.22it/s]",
            "\r  8%|▊         | 586/7500 [00:01\u003c00:16, 412.58it/s]",
            "\r  8%|▊         | 630/7500 [00:01\u003c00:16, 419.25it/s]",
            "\r  9%|▉         | 676/7500 [00:01\u003c00:15, 430.69it/s]",
            "\r 10%|▉         | 723/7500 [00:01\u003c00:15, 441.77it/s]",
            "\r 10%|█         | 771/7500 [00:01\u003c00:14, 451.32it/s]",
            "\r 11%|█         | 818/7500 [00:01\u003c00:14, 455.46it/s]",
            "\r 12%|█▏        | 864/7500 [00:02\u003c00:17, 369.78it/s]",
            "\r 12%|█▏        | 908/7500 [00:02\u003c00:17, 387.35it/s]",
            "\r 13%|█▎        | 957/7500 [00:02\u003c00:15, 411.25it/s]",
            "\r 13%|█▎        | 1004/7500 [00:02\u003c00:15, 427.25it/s]",
            "\r 14%|█▍        | 1050/7500 [00:02\u003c00:14, 436.57it/s]",
            "\r 15%|█▍        | 1097/7500 [00:02\u003c00:14, 444.83it/s]",
            "\r 15%|█▌        | 1143/7500 [00:02\u003c00:14, 440.26it/s]",
            "\r 16%|█▌        | 1188/7500 [00:02\u003c00:14, 436.69it/s]",
            "\r 16%|█▋        | 1235/7500 [00:02\u003c00:14, 444.89it/s]",
            "\r 17%|█▋        | 1283/7500 [00:03\u003c00:13, 449.74it/s]",
            "\r 18%|█▊        | 1329/7500 [00:03\u003c00:14, 436.04it/s]",
            "\r 18%|█▊        | 1376/7500 [00:03\u003c00:13, 443.18it/s]",
            "\r 19%|█▉        | 1423/7500 [00:03\u003c00:13, 448.34it/s]",
            "\r 20%|█▉        | 1469/7500 [00:03\u003c00:13, 451.75it/s]",
            "\r 20%|██        | 1515/7500 [00:03\u003c00:13, 452.88it/s]",
            "\r 21%|██        | 1563/7500 [00:03\u003c00:12, 459.37it/s]",
            "\r 21%|██▏       | 1610/7500 [00:03\u003c00:12, 457.08it/s]",
            "\r 22%|██▏       | 1658/7500 [00:03\u003c00:12, 462.40it/s]",
            "\r 23%|██▎       | 1705/7500 [00:03\u003c00:12, 456.54it/s]",
            "\r 23%|██▎       | 1751/7500 [00:04\u003c00:13, 435.46it/s]",
            "\r 24%|██▍       | 1797/7500 [00:04\u003c00:12, 441.27it/s]",
            "\r 25%|██▍       | 1842/7500 [00:04\u003c00:12, 438.66it/s]",
            "\r 25%|██▌       | 1887/7500 [00:04\u003c00:13, 430.61it/s]",
            "\r 26%|██▌       | 1931/7500 [00:04\u003c00:13, 416.17it/s]",
            "\r 26%|██▋       | 1973/7500 [00:04\u003c00:13, 399.44it/s]",
            "\r 27%|██▋       | 2014/7500 [00:04\u003c00:13, 393.26it/s]",
            "\r 27%|██▋       | 2055/7500 [00:04\u003c00:13, 396.99it/s]",
            "\r 28%|██▊       | 2096/7500 [00:04\u003c00:13, 399.65it/s]",
            "\r 28%|██▊       | 2137/7500 [00:05\u003c00:13, 402.68it/s]",
            "\r 29%|██▉       | 2178/7500 [00:05\u003c00:13, 403.64it/s]",
            "\r 30%|██▉       | 2219/7500 [00:05\u003c00:13, 403.17it/s]",
            "\r 30%|███       | 2260/7500 [00:05\u003c00:13, 399.28it/s]",
            "\r 31%|███       | 2304/7500 [00:05\u003c00:12, 410.68it/s]",
            "\r 31%|███▏      | 2352/7500 [00:05\u003c00:12, 425.85it/s]",
            "\r 32%|███▏      | 2400/7500 [00:05\u003c00:11, 438.35it/s]",
            "\r 33%|███▎      | 2445/7500 [00:05\u003c00:11, 427.91it/s]",
            "\r 33%|███▎      | 2489/7500 [00:05\u003c00:12, 409.77it/s]",
            "\r 34%|███▎      | 2531/7500 [00:05\u003c00:12, 400.97it/s]",
            "\r 34%|███▍      | 2575/7500 [00:06\u003c00:11, 410.76it/s]",
            "\r 35%|███▍      | 2621/7500 [00:06\u003c00:11, 423.23it/s]",
            "\r 36%|███▌      | 2665/7500 [00:06\u003c00:11, 426.89it/s]",
            "\r 36%|███▌      | 2708/7500 [00:06\u003c00:11, 413.02it/s]",
            "\r 37%|███▋      | 2750/7500 [00:06\u003c00:12, 368.59it/s]",
            "\r 37%|███▋      | 2791/7500 [00:06\u003c00:12, 380.09it/s]",
            "\r 38%|███▊      | 2838/7500 [00:06\u003c00:11, 402.20it/s]",
            "\r 38%|███▊      | 2883/7500 [00:06\u003c00:11, 412.00it/s]",
            "\r 39%|███▉      | 2925/7500 [00:06\u003c00:12, 380.61it/s]",
            "\r 40%|███▉      | 2965/7500 [00:07\u003c00:11, 385.11it/s]",
            "\r 40%|████      | 3007/7500 [00:07\u003c00:11, 393.83it/s]",
            "\r 41%|████      | 3047/7500 [00:07\u003c00:11, 382.06it/s]",
            "\r 41%|████      | 3086/7500 [00:07\u003c00:12, 361.94it/s]",
            "\r 42%|████▏     | 3130/7500 [00:07\u003c00:11, 380.30it/s]",
            "\r 42%|████▏     | 3178/7500 [00:07\u003c00:10, 404.55it/s]",
            "\r 43%|████▎     | 3222/7500 [00:07\u003c00:10, 414.55it/s]",
            "\r 44%|████▎     | 3267/7500 [00:07\u003c00:10, 422.19it/s]",
            "\r 44%|████▍     | 3311/7500 [00:07\u003c00:09, 427.38it/s]",
            "\r 45%|████▍     | 3358/7500 [00:08\u003c00:09, 438.12it/s]",
            "\r 45%|████▌     | 3404/7500 [00:08\u003c00:09, 443.18it/s]",
            "\r 46%|████▌     | 3449/7500 [00:08\u003c00:10, 396.91it/s]",
            "\r 47%|████▋     | 3495/7500 [00:08\u003c00:09, 413.92it/s]",
            "\r 47%|████▋     | 3542/7500 [00:08\u003c00:09, 426.95it/s]",
            "\r 48%|████▊     | 3589/7500 [00:08\u003c00:08, 437.79it/s]",
            "\r 48%|████▊     | 3634/7500 [00:08\u003c00:09, 392.31it/s]",
            "\r 49%|████▉     | 3675/7500 [00:08\u003c00:09, 384.05it/s]",
            "\r 50%|████▉     | 3715/7500 [00:08\u003c00:10, 357.44it/s]",
            "\r 50%|█████     | 3752/7500 [00:09\u003c00:11, 335.58it/s]",
            "\r 50%|█████     | 3787/7500 [00:09\u003c00:11, 326.46it/s]",
            "\r 51%|█████     | 3821/7500 [00:09\u003c00:11, 307.13it/s]",
            "\r 51%|█████▏    | 3853/7500 [00:09\u003c00:11, 309.08it/s]",
            "\r 52%|█████▏    | 3886/7500 [00:09\u003c00:11, 311.49it/s]",
            "\r 52%|█████▏    | 3926/7500 [00:09\u003c00:10, 331.98it/s]",
            "\r 53%|█████▎    | 3969/7500 [00:09\u003c00:09, 355.45it/s]",
            "\r 53%|█████▎    | 4006/7500 [00:09\u003c00:09, 352.52it/s]",
            "\r 54%|█████▍    | 4042/7500 [00:09\u003c00:10, 344.55it/s]",
            "\r 54%|█████▍    | 4077/7500 [00:10\u003c00:10, 328.62it/s]",
            "\r 55%|█████▍    | 4118/7500 [00:10\u003c00:09, 349.41it/s]",
            "\r 56%|█████▌    | 4163/7500 [00:10\u003c00:08, 372.66it/s]",
            "\r 56%|█████▌    | 4211/7500 [00:10\u003c00:08, 398.47it/s]",
            "\r 57%|█████▋    | 4257/7500 [00:10\u003c00:07, 412.89it/s]",
            "\r 57%|█████▋    | 4302/7500 [00:10\u003c00:07, 422.19it/s]",
            "\r 58%|█████▊    | 4346/7500 [00:10\u003c00:07, 426.14it/s]",
            "\r 59%|█████▊    | 4391/7500 [00:10\u003c00:07, 433.02it/s]",
            "\r 59%|█████▉    | 4436/7500 [00:10\u003c00:07, 436.71it/s]",
            "\r 60%|█████▉    | 4480/7500 [00:10\u003c00:06, 436.37it/s]",
            "\r 60%|██████    | 4527/7500 [00:11\u003c00:06, 443.42it/s]",
            "\r 61%|██████    | 4575/7500 [00:11\u003c00:06, 452.51it/s]",
            "\r 62%|██████▏   | 4623/7500 [00:11\u003c00:06, 459.09it/s]",
            "\r 62%|██████▏   | 4670/7500 [00:11\u003c00:06, 432.95it/s]",
            "\r 63%|██████▎   | 4714/7500 [00:11\u003c00:07, 393.07it/s]",
            "\r 63%|██████▎   | 4755/7500 [00:11\u003c00:07, 350.09it/s]",
            "\r 64%|██████▍   | 4800/7500 [00:11\u003c00:07, 373.20it/s]",
            "\r 65%|██████▍   | 4839/7500 [00:11\u003c00:07, 371.60it/s]",
            "\r 65%|██████▌   | 4878/7500 [00:12\u003c00:07, 362.23it/s]",
            "\r 66%|██████▌   | 4916/7500 [00:12\u003c00:07, 349.16it/s]",
            "\r 66%|██████▌   | 4952/7500 [00:12\u003c00:07, 349.26it/s]",
            "\r 67%|██████▋   | 4995/7500 [00:12\u003c00:06, 370.10it/s]",
            "\r 67%|██████▋   | 5033/7500 [00:12\u003c00:06, 366.48it/s]",
            "\r 68%|██████▊   | 5071/7500 [00:12\u003c00:07, 344.27it/s]",
            "\r 68%|██████▊   | 5107/7500 [00:12\u003c00:07, 329.21it/s]",
            "\r 69%|██████▊   | 5144/7500 [00:12\u003c00:06, 340.36it/s]",
            "\r 69%|██████▉   | 5179/7500 [00:12\u003c00:06, 336.27it/s]",
            "\r 70%|██████▉   | 5213/7500 [00:12\u003c00:06, 335.35it/s]",
            "\r 70%|███████   | 5250/7500 [00:13\u003c00:06, 343.93it/s]",
            "\r 70%|███████   | 5286/7500 [00:13\u003c00:06, 347.26it/s]",
            "\r 71%|███████   | 5324/7500 [00:13\u003c00:06, 354.81it/s]",
            "\r 71%|███████▏  | 5360/7500 [00:13\u003c00:06, 334.43it/s]",
            "\r 72%|███████▏  | 5395/7500 [00:13\u003c00:06, 338.95it/s]",
            "\r 72%|███████▏  | 5430/7500 [00:13\u003c00:06, 341.49it/s]",
            "\r 73%|███████▎  | 5465/7500 [00:13\u003c00:06, 331.08it/s]",
            "\r 73%|███████▎  | 5502/7500 [00:13\u003c00:05, 338.50it/s]",
            "\r 74%|███████▍  | 5537/7500 [00:13\u003c00:06, 324.66it/s]",
            "\r 74%|███████▍  | 5570/7500 [00:14\u003c00:06, 313.64it/s]",
            "\r 75%|███████▍  | 5602/7500 [00:14\u003c00:06, 293.80it/s]",
            "\r 75%|███████▌  | 5639/7500 [00:14\u003c00:05, 311.95it/s]",
            "\r 76%|███████▌  | 5677/7500 [00:14\u003c00:05, 329.07it/s]",
            "\r 76%|███████▌  | 5712/7500 [00:14\u003c00:05, 331.56it/s]",
            "\r 77%|███████▋  | 5747/7500 [00:14\u003c00:05, 334.75it/s]",
            "\r 77%|███████▋  | 5781/7500 [00:14\u003c00:05, 334.27it/s]",
            "\r 78%|███████▊  | 5815/7500 [00:14\u003c00:05, 327.25it/s]",
            "\r 78%|███████▊  | 5848/7500 [00:14\u003c00:05, 293.89it/s]",
            "\r 78%|███████▊  | 5884/7500 [00:15\u003c00:05, 310.22it/s]",
            "\r 79%|███████▉  | 5918/7500 [00:15\u003c00:05, 315.26it/s]",
            "\r 79%|███████▉  | 5951/7500 [00:15\u003c00:04, 315.27it/s]",
            "\r 80%|███████▉  | 5983/7500 [00:15\u003c00:04, 305.32it/s]",
            "\r 80%|████████  | 6023/7500 [00:15\u003c00:04, 327.03it/s]",
            "\r 81%|████████  | 6067/7500 [00:15\u003c00:04, 353.47it/s]",
            "\r 81%|████████▏ | 6109/7500 [00:15\u003c00:03, 371.10it/s]",
            "\r 82%|████████▏ | 6148/7500 [00:15\u003c00:03, 362.87it/s]",
            "\r 82%|████████▏ | 6186/7500 [00:15\u003c00:03, 355.45it/s]",
            "\r 83%|████████▎ | 6223/7500 [00:16\u003c00:03, 358.64it/s]",
            "\r 83%|████████▎ | 6261/7500 [00:16\u003c00:03, 363.75it/s]",
            "\r 84%|████████▍ | 6303/7500 [00:16\u003c00:03, 377.96it/s]",
            "\r 85%|████████▍ | 6349/7500 [00:16\u003c00:02, 399.31it/s]",
            "\r 85%|████████▌ | 6391/7500 [00:16\u003c00:02, 405.30it/s]",
            "\r 86%|████████▌ | 6437/7500 [00:16\u003c00:02, 419.14it/s]",
            "\r 86%|████████▋ | 6482/7500 [00:16\u003c00:02, 425.53it/s]",
            "\r 87%|████████▋ | 6528/7500 [00:16\u003c00:02, 434.09it/s]",
            "\r 88%|████████▊ | 6572/7500 [00:16\u003c00:02, 434.53it/s]",
            "\r 88%|████████▊ | 6617/7500 [00:16\u003c00:02, 439.06it/s]",
            "\r 89%|████████▉ | 6663/7500 [00:17\u003c00:01, 443.85it/s]",
            "\r 89%|████████▉ | 6708/7500 [00:17\u003c00:02, 340.48it/s]",
            "\r 90%|█████████ | 6751/7500 [00:17\u003c00:02, 362.25it/s]",
            "\r 91%|█████████ | 6794/7500 [00:17\u003c00:01, 380.21it/s]",
            "\r 91%|█████████ | 6839/7500 [00:17\u003c00:01, 396.63it/s]",
            "\r 92%|█████████▏| 6883/7500 [00:17\u003c00:01, 406.46it/s]",
            "\r 92%|█████████▏| 6926/7500 [00:17\u003c00:01, 412.03it/s]",
            "\r 93%|█████████▎| 6969/7500 [00:17\u003c00:01, 404.33it/s]",
            "\r 94%|█████████▎| 7014/7500 [00:17\u003c00:01, 415.85it/s]",
            "\r 94%|█████████▍| 7057/7500 [00:18\u003c00:01, 389.22it/s]",
            "\r 95%|█████████▍| 7097/7500 [00:18\u003c00:01, 367.52it/s]",
            "\r 95%|█████████▌| 7137/7500 [00:18\u003c00:00, 375.63it/s]",
            "\r 96%|█████████▌| 7184/7500 [00:18\u003c00:00, 399.70it/s]",
            "\r 96%|█████████▋| 7230/7500 [00:18\u003c00:00, 414.94it/s]",
            "\r 97%|█████████▋| 7278/7500 [00:18\u003c00:00, 430.21it/s]",
            "\r 98%|█████████▊| 7322/7500 [00:18\u003c00:00, 428.05it/s]",
            "\r 98%|█████████▊| 7366/7500 [00:18\u003c00:00, 431.57it/s]",
            "\r 99%|█████████▉| 7413/7500 [00:18\u003c00:00, 442.40it/s]",
            "\r 99%|█████████▉| 7458/7500 [00:18\u003c00:00, 444.65it/s]",
            "\r100%|██████████| 7500/7500 [00:19\u003c00:00, 393.07it/s]",
            "\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "(1, 60, 8)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 17
        }
      ],
      "source": "train_data\u003dXWDataset(os.path.join(\"./data\",\"sensor_train.csv\"),with_label\u003dTrue)\ntest_data\u003dXWDataset(os.path.join(\"./data\",\"sensor_test.csv\"),with_label\u003dFalse,)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(1, 60, 8) (19,)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "feature,label\u003dnext(iter(train_data))\nprint(feature.shape,label.shape)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": "mapping \u003d {0: \u0027A_0\u0027, 1: \u0027A_1\u0027, 2: \u0027A_2\u0027, 3: \u0027A_3\u0027,\n           4: \u0027D_4\u0027, 5: \u0027A_5\u0027, 6: \u0027B_1\u0027, 7: \u0027B_5\u0027,\n           8: \u0027B_2\u0027, 9: \u0027B_3\u0027, 10: \u0027B_0\u0027, 11: \u0027A_6\u0027,\n           12: \u0027C_1\u0027, 13: \u0027C_3\u0027, 14: \u0027C_0\u0027, 15: \u0027B_6\u0027,\n           16: \u0027C_2\u0027, 17: \u0027C_5\u0027, 18: \u0027C_6\u0027}\ndef get_acc_combo():\n    def combo(y, y_pred):\n        # 数值ID与行为编码的对应关系\n        mapping \u003d {0: \u0027A_0\u0027, 1: \u0027A_1\u0027, 2: \u0027A_2\u0027, 3: \u0027A_3\u0027,\n            4: \u0027D_4\u0027, 5: \u0027A_5\u0027, 6: \u0027B_1\u0027,7: \u0027B_5\u0027,\n            8: \u0027B_2\u0027, 9: \u0027B_3\u0027, 10: \u0027B_0\u0027, 11: \u0027A_6\u0027,\n            12: \u0027C_1\u0027, 13: \u0027C_3\u0027, 14: \u0027C_0\u0027, 15: \u0027B_6\u0027,\n            16: \u0027C_2\u0027, 17: \u0027C_5\u0027, 18: \u0027C_6\u0027}\n        # 将行为ID转为编码\n        code_y, code_y_pred \u003d mapping[int(y)], mapping[int(y_pred)]\n        if code_y \u003d\u003d code_y_pred: #编码完全相同得分1.0\n            return 1.0\n        elif code_y.split(\"_\")[0] \u003d\u003d code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n            return 1.0/7\n        elif code_y.split(\"_\")[1] \u003d\u003d code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n            return 1.0/3\n        else:\n            return 0.0\n    confusionMatrix\u003dnp.zeros((19,19))\n    for i in range(19):\n        for j in range(19):\n            confusionMatrix[i,j]\u003dcombo(i,j)\n    def acc_combo(y, y_pred):\n        y\u003dnp.argmax(y,axis\u003d1)\n        y_pred \u003d np.argmax(y_pred, axis\u003d1)\n        scores\u003dconfusionMatrix[y,y_pred]\n        return np.mean(scores)\n    return acc_combo\n\ndef get_acc_func():\n    confusionMatrix\u003dnp.zeros((19,19))\n    for i in range(19):\n            confusionMatrix[i,i]\u003d1\n    def acc_func(y, y_pred):\n        y\u003dnp.argmax(y,axis\u003d1)\n        y_pred \u003d np.argmax(y_pred, axis\u003d1)\n        scores\u003dconfusionMatrix[y,y_pred]\n        return np.mean(scores)\n    return acc_func\nacc_combo_func\u003dget_acc_combo()\nacc_func\u003dget_acc_func()\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 构造评价指标",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": "class XWMetrics(object):\n\n    def __init__(self):\n        pass\n        self.labels\u003d[]\n        self.scores\u003d[]\n\n    def reset(self):\n        self.labels\u003d[]\n        self.scores\u003d[]\n\n    def add_batch(self,labels,scores):\n        self.labels.append(labels)\n        self.scores.append(scores)\n\n    def apply(self):\n\n        labels\u003dnp.concatenate(self.labels,axis\u003d0)\n        scores\u003dnp.concatenate(self.scores,axis\u003d0)\n        acc_combo\u003dacc_combo_func(labels,scores)\n        acc\u003dacc_func(labels,scores)\n        return {\"acc\":acc,\"acc_combo\":acc_combo}",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 将pytorch构造成类似keras的训练操作",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": "import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport  pandas as pd\nimport  os\nfrom tqdm import tqdm\nfrom collections import Iterable\nimport numpy as np\nclass Agent(object):\n    def __init__(self,model,device_info,save_dir):\n        \n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        self.save_dir\u003dsave_dir\n        self.device \u003ddevice_info[\"device\"]\n        # self.saver\u003dNone\n        self.model\u003dmodel\n        self.ParallelModel \u003d torch.nn.DataParallel(model, device_ids\u003d device_info[\"device_ids\"])\n        self.ParallelModel.to(self.device)\n        \n    def summary(self):\n        print(self.model)\n\n    def compile(self,loss_dict,optimizer,metrics):\n        self.loss_dict\u003dloss_dict\n        self.optimizer\u003doptimizer\n        self.metrics\u003dmetrics\n\n    def fit_generator(self,dataloader,epochs, validation_data,reduceLR\u003dNone,earlyStopping\u003dNone,**kwargs):\n        metric\u003dself.metrics\n        loss_dict\u003d self.loss_dict\n        valid_acc\u003d[]\n        for epoch  in range(epochs):\n            print(\"epoch:{}-lr:{:.8f}\".format(epoch,self.optimizer.state_dict()[\u0027param_groups\u0027][0][\u0027lr\u0027])+\"-\"*5)\n            #train\n            phase\u003d\"train\"\n            self.model.train()\n            metric.reset()\n            result_epoch\u003dself.iter_on_a_epoch(phase,dataloader,loss_dict,metric)\n\n            # log\n            s \u003d \u0027phase:{}-\u0027.format(phase)\n            for key, val in result_epoch.items():\n                if not isinstance(val, Iterable):\n                    s +\u003d \",{}:{:.4f}\".format(key, val)\n            print(s)\n\n            #valid\n            phase \u003d \"valid\"\n            metric.reset()\n            self.model.eval()\n            valid_dataloader\u003dDataLoader(validation_data,batch_size\u003d1024,drop_last\u003dFalse)\n            result_epoch \u003d self.iter_on_a_epoch( phase, valid_dataloader, loss_dict, metric)\n            valid_acc.append(result_epoch[\"acc_metrics\"])\n            # log\n            s \u003d \u0027phase:{}---\u0027.format( phase)\n            for key, val in result_epoch.items():\n                if not isinstance(val, Iterable):\n                    s +\u003d \",{}:{:.4f}\".format(key, val)\n            print(s)\n\n            #保存模型\n            # 保存验证集准确率\u003e0.7的当前最高准确率权重\n            if (valid_acc[-1] \u003e 0.7 and valid_acc[-1] \u003d\u003d max(valid_acc)) or (epoch\u003d\u003depochs-1):\n                save_name\u003d\"epo_{}-score_{:.5f}.pth\".format(epoch, valid_acc[-1])\n                self.save_model(save_name)\n            # recude lr\n            if reduceLR is not  None:\n                epoch_loss \u003d sum([val for key, val in result_epoch.items() if \"loss\" in key])\n                reduceLR.step(valid_acc[-1], epoch)\n            # earlyStopping\n            if earlyStopping is not None:\n                earlyStopping.step()\n\n    def iter_on_a_epoch(self, phase, dataloader,loss_dict, metric, **kwargs):\n        assert  phase in [\"train\",\"valid\",\"test\"]\n        result_epoch \u003d {\"count\": 0,}\n        metric.reset()\n        # for cnt_batch, batch in zip(tqdm(range(1, len(dataloader) + 1)), dataloader):\n        for cnt_batch, batch in zip(range(1, len(dataloader) + 1), dataloader):\n            result_batch \u003d self.iter_on_a_batch(batch, loss_dict\u003dloss_dict, phase\u003dphase)\n            #返回结果\n            score_batch,label_batch,img_batch\u003dresult_batch[\"score_batch\"],result_batch[\"label_batch\"],result_batch[\"img_batch\"]\n\n            metric.add_batch(label_batch.astype(np.float),score_batch.astype(np.float))\n            # print(np.array(metric.labels).shape)\n            # 返回损失\n            result_epoch[\"count\"] +\u003d label_batch.shape[0]\n            for key, val in result_batch[\"loss\"].items():\n                key \u003d key + \"_loss\"\n                if key not in result_epoch.keys(): result_epoch[key] \u003d []\n                result_epoch[key].append(val)\n            # ###### 打印loss\n            # if phase \u003d\u003d \"train\":\n            #     cul_lr \u003d self.optimizer_ft.state_dict()[\u0027param_groups\u0027][0][\u0027lr\u0027]\n            #     s \u003d \"epoch:{},batch:{},lr:{:.5f}\".format(epoch, cnt_batch, float(cul_lr))\n            #     for key, loss in result[\"loss\"].items():\n            #         s +\u003d \",{}:{:.4f}\".format(key, float(loss))\n            #     # self.logger.info(s)\n            #     print(s)\n\n        # 将所有loss平均\n        for key, val in result_epoch.items():\n            if \"loss\" in key:\n                result_epoch[key] \u003d np.array(val).sum() / len(val)\n\n        metric_dict\u003dmetric.apply()\n        for key,val in metric_dict.items():\n            key\u003dkey+\"_metrics\"\n            result_epoch[key]\u003dval\n        return result_epoch\n\n    def iter_on_a_batch(self, batch,  phase,loss_dict):\n        assert phase in [\"train\", \"valid\", \"test\",],print(phase)\n        # self.model.setMode(\"segment\")\n        img_tensor, label_tensor \u003d batch\n        model\u003dself.ParallelModel\n        optimizer\u003dself.optimizer\n        device\u003dself.device\n        # forward\n        img_rensor \u003d self.type_tran(img_tensor)\n\n        label_tensor \u003dself.type_tran(label_tensor)\n        score_tensor \u003d model(img_rensor)\n        # update_mask_batch\u003dmask_tensor.detach().cpu().numpy()\n        ###### cul loss\n        losses \u003d dict()\n        if phase in [\"train\", \"valid\", \"test\"]:\n            for name,loss in loss_dict.items():\n                loss_val \u003d loss(score_tensor, label_tensor)\n\n                losses[name] \u003d loss_val\n        ##### backward\n        if phase in [\"train\"]:\n            assert isinstance(losses, dict)\n            model.zero_grad()\n            loss_sum \u003d sum(list(losses.values()))\n            loss_sum.backward()\n            optimizer.step()\n        #### return\n\n        score_tensor\u003dscore_tensor.softmax(dim\u003d-1)\n        img_batch \u003d img_rensor.detach().cpu().numpy()\n        label_batch \u003d label_tensor.detach().cpu().numpy()\n        score_batch \u003d score_tensor.detach().cpu().numpy()\n        result \u003d {\"img_batch\": img_batch,\"label_batch\": label_batch, \"score_batch\": score_batch}\n        if phase in [\"train\", \"valid\", \"test\"]:\n            sum_loss \u003d 0\n            for key, loss in losses.items():\n                losses[key] \u003d float(loss)\n                sum_loss +\u003d float(loss)\n            # losses[\"sum\"] \u003d sum_loss\n        result[\"loss\"] \u003d losses\n        return result\n\n    def load_weights(self,load_name):\n        save_dir \u003d self.save_dir + \"/model/\"\n        load_path\u003dos.path.join(save_dir,load_name)\n        if os.path.exists(load_path):\n            pthfile \u003d torch.load(load_path)\n            # print(pthfile.keys())\n            self.model.load_state_dict(pthfile, strict\u003dTrue)\n            print(\"load weights from {}\".format(load_path))\n        else:\n            raise  Exception(\"Load model falied, {} is not existing!!!\".format(load_path))\n\n    def save_model(self,save_name):\n        save_dir\u003dself.save_dir+\"/model/\"\n        if not  os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        save_path\u003dos.path.join(save_dir,save_name)\n        print(\"save weights to {}\".format(save_path))\n        torch.save(self.model.state_dict(),save_path)\n\n\n    def load_best_model(self):\n\n        load_names\u003d[  name for name in os.listdir(self.save_dir+\"/model/\") if name.endswith(\".pth\")]\n        load_name \u003d sorted(load_names, key\u003dlambda x: float(x.split(\".\")[-2]),\n                           reverse\u003dTrue)[0]\n        self.load_weights(load_name)\n\n    def predict(self,data,phase,batch_size\u003d1024):\n        # valid\n        dataloader \u003d DataLoader(data, batch_size\u003dbatch_size, drop_last\u003dFalse,shuffle\u003dFalse)\n        score_batchs\u003d[]\n        result_epoch \u003d {\"count\": 0,}\n        for cnt_batch, batch in zip(tqdm(range(1, len(dataloader) + 1)), dataloader):\n            result_batch \u003d self.infer_on_a_batch(batch)\n            #返回结果\n            score_batch,img_batch\u003dresult_batch[\"score_batch\"],result_batch[\"img_batch\"]\n            score_batchs.append(score_batch)\n            # 返回损失\n            result_epoch[\"count\"] +\u003d score_batch.shape[0]\n        dim\u003dscore_batchs[0].shape[-1]\n        score_array\u003dnp.concatenate(score_batchs,axis\u003d0)\n\n        df \u003d pd.DataFrame(score_array)\n        df.to_csv(self.save_dir + \"/{}_score.csv\".format(phase))\n\n        return score_array\n\n    def infer_on_a_batch(self, batch):\n        img_tensor \u003d batch\n        # forward\n        img_rensor \u003d self.type_tran(img_tensor)\n        score_tensor \u003d self.ParallelModel(img_rensor)\n        score_tensor\u003dscore_tensor.softmax(dim\u003d-1)\n        #### return\n        img_batch \u003d img_rensor.detach().cpu().numpy()\n        score_batch \u003d score_tensor.detach().cpu().numpy()\n        result \u003d {\"img_batch\": img_batch, \"score_batch\": score_batch}\n        return result\n\n    def type_tran(self,data):\n        return  data.to(torch.float32).to(self.device)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 构造CNN模型",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "class Model(nn.Module):\n    def __init__(self, num_classes\u003d19):\n        super(Model, self).__init__()\n\n        # input: 1, num, features_num\n        base_channel\u003d64\n        self.features \u003d nn.Sequential(\n            # 1\n            nn.Conv2d(1, base_channel, kernel_size\u003d(3, 3),stride\u003d(1,1),padding\u003d(1,1)),\n            nn.BatchNorm2d(base_channel),\n            nn.ReLU(inplace\u003dTrue),\n            # 2\n            nn.Conv2d(base_channel, base_channel*2,kernel_size\u003d(3, 3), stride\u003d(1,1),padding\u003d(1,1)),\n            nn.BatchNorm2d(base_channel*2),\n            nn.ReLU(inplace\u003dTrue),\n            nn.MaxPool2d(2,2),\n            # 3\n            nn.Conv2d(base_channel*2, base_channel*4, kernel_size\u003d(3, 3), stride\u003d(1,1),padding\u003d(1,1)),\n            nn.BatchNorm2d(base_channel*4),\n            nn.ReLU(inplace\u003dTrue),\n            nn.Conv2d(base_channel * 4, base_channel * 4, kernel_size\u003d(3, 3), stride\u003d(1, 1), padding\u003d(1, 1)),\n            nn.BatchNorm2d(base_channel * 4),\n            nn.ReLU(inplace\u003dTrue),\n            # last\n            nn.AdaptiveMaxPool2d((1, 1)),\n            nn.Dropout(0.3),\n        )\n        self.classier \u003d nn.Linear(base_channel*4, num_classes)\n        self._initialize_weights()\n\n    def forward(self, x):\n        x \u003d self.features(x)\n\n        x \u003d x.view(x.shape[0], -1)\n        x \u003d self.classier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv2d):\n                # nn.init.constant_(m.weight, 0)\n                # nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.kaiming_normal_(m.weight, mode\u003d\u0027fan_out\u0027, nonlinearity\u003d\u0027relu\u0027)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n                    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": "class CELoss(nn.Module):\n\n    def __init__(self, reduction\u003d\u0027mean\u0027):\n        super().__init__()\n\n        self.log_softmax \u003d nn.LogSoftmax(dim\u003d1)\n        self.nllloss\u003d  nn.NLLLoss(reduction\u003dreduction)\n    def forward(self, x, target):\n\n        if x.size(0) !\u003d target.size(0):\n            raise ValueError(\u0027Expected input batchsize ({}) to match target batch_size({})\u0027\n                             .format(x.size(0), target.size(0)))\n\n        if x.dim() \u003c 2:\n            raise ValueError(\u0027Expected input tensor to have least 2 dimensions(got {})\u0027\n                             .format(x.size(0)))\n\n        if x.dim() !\u003d 2:\n            raise ValueError(\u0027Only 2 dimension tensor are implemented, (got {})\u0027\n                             .format(x.size()))\n\n        x \u003d self.log_softmax(x)\n        target\u003dtorch.argmax(target,dim\u003d-1)\n        loss\u003dself.nllloss(x,target\u003dtarget)\n        return loss\n    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7292 [00:00\u003c?, ?it/s]",
            "\r  0%|          | 22/7292 [00:00\u003c00:33, 217.81it/s]",
            "\r  1%|          | 61/7292 [00:00\u003c00:28, 250.59it/s]",
            "\r  1%|          | 88/7292 [00:00\u003c00:28, 255.38it/s]",
            "\r  2%|▏         | 128/7292 [00:00\u003c00:25, 286.42it/s]",
            "\r  2%|▏         | 163/7292 [00:00\u003c00:23, 301.36it/s]",
            "\r  3%|▎         | 204/7292 [00:00\u003c00:21, 326.60it/s]",
            "\r  3%|▎         | 246/7292 [00:00\u003c00:20, 349.07it/s]",
            "\r  4%|▍         | 288/7292 [00:00\u003c00:19, 367.69it/s]",
            "\r  5%|▍         | 335/7292 [00:00\u003c00:17, 391.43it/s]",
            "\r  5%|▌         | 375/7292 [00:01\u003c00:17, 388.22it/s]",
            "\r  6%|▌         | 415/7292 [00:01\u003c00:20, 328.08it/s]",
            "\r  6%|▋         | 459/7292 [00:01\u003c00:19, 355.17it/s]",
            "\r  7%|▋         | 497/7292 [00:01\u003c00:18, 360.21it/s]",
            "\r  7%|▋         | 539/7292 [00:01\u003c00:17, 375.17it/s]",
            "\r  8%|▊         | 581/7292 [00:01\u003c00:17, 387.37it/s]",
            "\r  9%|▊         | 622/7292 [00:01\u003c00:16, 392.78it/s]",
            "\r  9%|▉         | 662/7292 [00:01\u003c00:23, 280.62it/s]",
            "\r 10%|▉         | 695/7292 [00:02\u003c00:22, 288.41it/s]",
            "\r 10%|▉         | 728/7292 [00:02\u003c00:23, 273.64it/s]",
            "\r 10%|█         | 758/7292 [00:02\u003c00:25, 254.24it/s]",
            "\r 11%|█         | 786/7292 [00:02\u003c00:25, 257.85it/s]",
            "\r 11%|█         | 817/7292 [00:02\u003c00:23, 270.84it/s]",
            "\r 12%|█▏        | 851/7292 [00:02\u003c00:22, 288.44it/s]",
            "\r 12%|█▏        | 882/7292 [00:02\u003c00:26, 241.56it/s]",
            "\r 13%|█▎        | 918/7292 [00:02\u003c00:23, 267.99it/s]",
            "\r 13%|█▎        | 965/7292 [00:02\u003c00:20, 306.45it/s]",
            "\r 14%|█▎        | 1002/7292 [00:03\u003c00:19, 322.26it/s]",
            "\r 14%|█▍        | 1045/7292 [00:03\u003c00:18, 347.01it/s]",
            "\r 15%|█▍        | 1088/7292 [00:03\u003c00:16, 367.38it/s]",
            "\r 15%|█▌        | 1128/7292 [00:03\u003c00:16, 375.55it/s]",
            "\r 16%|█▌        | 1168/7292 [00:03\u003c00:17, 359.71it/s]",
            "\r 17%|█▋        | 1213/7292 [00:03\u003c00:15, 381.76it/s]",
            "\r 17%|█▋        | 1253/7292 [00:03\u003c00:16, 377.22it/s]",
            "\r 18%|█▊        | 1296/7292 [00:03\u003c00:15, 391.64it/s]",
            "\r 18%|█▊        | 1341/7292 [00:03\u003c00:14, 405.30it/s]",
            "\r 19%|█▉        | 1383/7292 [00:04\u003c00:14, 395.70it/s]",
            "\r 20%|█▉        | 1424/7292 [00:04\u003c00:14, 398.70it/s]",
            "\r 20%|██        | 1470/7292 [00:04\u003c00:14, 414.18it/s]",
            "\r 21%|██        | 1514/7292 [00:04\u003c00:13, 420.42it/s]",
            "\r 21%|██▏       | 1557/7292 [00:04\u003c00:16, 342.36it/s]",
            "\r 22%|██▏       | 1597/7292 [00:04\u003c00:16, 355.93it/s]",
            "\r 23%|██▎       | 1641/7292 [00:04\u003c00:14, 377.56it/s]",
            "\r 23%|██▎       | 1688/7292 [00:04\u003c00:14, 400.21it/s]",
            "\r 24%|██▎       | 1730/7292 [00:04\u003c00:14, 393.38it/s]",
            "\r 24%|██▍       | 1775/7292 [00:05\u003c00:13, 408.80it/s]",
            "\r 25%|██▍       | 1819/7292 [00:05\u003c00:13, 415.34it/s]",
            "\r 26%|██▌       | 1862/7292 [00:05\u003c00:13, 406.52it/s]",
            "\r 26%|██▌       | 1904/7292 [00:05\u003c00:13, 406.87it/s]",
            "\r 27%|██▋       | 1950/7292 [00:05\u003c00:12, 419.19it/s]",
            "\r 27%|██▋       | 1994/7292 [00:05\u003c00:12, 424.00it/s]",
            "\r 28%|██▊       | 2038/7292 [00:05\u003c00:12, 426.18it/s]",
            "\r 29%|██▊       | 2083/7292 [00:05\u003c00:12, 433.05it/s]",
            "\r 29%|██▉       | 2127/7292 [00:05\u003c00:11, 431.29it/s]",
            "\r 30%|██▉       | 2174/7292 [00:05\u003c00:11, 442.19it/s]",
            "\r 30%|███       | 2219/7292 [00:06\u003c00:11, 438.03it/s]",
            "\r 31%|███       | 2263/7292 [00:06\u003c00:11, 429.61it/s]",
            "\r 32%|███▏      | 2309/7292 [00:06\u003c00:11, 435.81it/s]",
            "\r 32%|███▏      | 2355/7292 [00:06\u003c00:11, 441.54it/s]",
            "\r 33%|███▎      | 2400/7292 [00:06\u003c00:11, 419.19it/s]",
            "\r 34%|███▎      | 2445/7292 [00:06\u003c00:11, 426.80it/s]",
            "\r 34%|███▍      | 2490/7292 [00:06\u003c00:11, 431.01it/s]",
            "\r 35%|███▍      | 2534/7292 [00:06\u003c00:11, 428.60it/s]",
            "\r 35%|███▌      | 2577/7292 [00:06\u003c00:11, 409.42it/s]",
            "\r 36%|███▌      | 2621/7292 [00:07\u003c00:11, 414.58it/s]",
            "\r 37%|███▋      | 2666/7292 [00:07\u003c00:10, 423.39it/s]",
            "\r 37%|███▋      | 2714/7292 [00:07\u003c00:10, 436.52it/s]",
            "\r 38%|███▊      | 2758/7292 [00:07\u003c00:11, 408.35it/s]",
            "\r 38%|███▊      | 2802/7292 [00:07\u003c00:10, 416.15it/s]",
            "\r 39%|███▉      | 2847/7292 [00:07\u003c00:10, 424.55it/s]",
            "\r 40%|███▉      | 2893/7292 [00:07\u003c00:10, 433.39it/s]",
            "\r 40%|████      | 2937/7292 [00:07\u003c00:10, 424.02it/s]",
            "\r 41%|████      | 2985/7292 [00:07\u003c00:09, 438.17it/s]",
            "\r 42%|████▏     | 3031/7292 [00:07\u003c00:09, 441.95it/s]",
            "\r 42%|████▏     | 3076/7292 [00:08\u003c00:09, 427.82it/s]",
            "\r 43%|████▎     | 3120/7292 [00:08\u003c00:10, 408.57it/s]",
            "\r 43%|████▎     | 3162/7292 [00:08\u003c00:10, 400.17it/s]",
            "\r 44%|████▍     | 3207/7292 [00:08\u003c00:09, 412.77it/s]",
            "\r 45%|████▍     | 3253/7292 [00:08\u003c00:09, 424.71it/s]",
            "\r 45%|████▌     | 3296/7292 [00:08\u003c00:09, 408.09it/s]",
            "\r 46%|████▌     | 3339/7292 [00:08\u003c00:09, 413.17it/s]",
            "\r 46%|████▋     | 3385/7292 [00:08\u003c00:09, 423.86it/s]",
            "\r 47%|████▋     | 3429/7292 [00:08\u003c00:09, 428.57it/s]",
            "\r 48%|████▊     | 3473/7292 [00:09\u003c00:11, 337.51it/s]",
            "\r 48%|████▊     | 3519/7292 [00:09\u003c00:10, 365.92it/s]",
            "\r 49%|████▉     | 3566/7292 [00:09\u003c00:09, 390.01it/s]",
            "\r 49%|████▉     | 3608/7292 [00:09\u003c00:09, 384.34it/s]",
            "\r 50%|█████     | 3649/7292 [00:09\u003c00:09, 391.64it/s]",
            "\r 51%|█████     | 3695/7292 [00:09\u003c00:08, 407.75it/s]",
            "\r 51%|█████▏    | 3741/7292 [00:09\u003c00:08, 420.98it/s]",
            "\r 52%|█████▏    | 3784/7292 [00:09\u003c00:08, 413.84it/s]",
            "\r 53%|█████▎    | 3829/7292 [00:09\u003c00:08, 422.87it/s]",
            "\r 53%|█████▎    | 3873/7292 [00:10\u003c00:08, 424.17it/s]",
            "\r 54%|█████▎    | 3916/7292 [00:10\u003c00:08, 419.58it/s]",
            "\r 54%|█████▍    | 3962/7292 [00:10\u003c00:07, 429.73it/s]",
            "\r 55%|█████▍    | 4006/7292 [00:10\u003c00:07, 414.44it/s]",
            "\r 56%|█████▌    | 4049/7292 [00:10\u003c00:07, 416.52it/s]",
            "\r 56%|█████▌    | 4094/7292 [00:10\u003c00:07, 422.41it/s]",
            "\r 57%|█████▋    | 4137/7292 [00:10\u003c00:07, 424.65it/s]",
            "\r 57%|█████▋    | 4182/7292 [00:10\u003c00:07, 429.50it/s]",
            "\r 58%|█████▊    | 4228/7292 [00:10\u003c00:06, 438.20it/s]",
            "\r 59%|█████▊    | 4273/7292 [00:10\u003c00:06, 439.11it/s]",
            "\r 59%|█████▉    | 4317/7292 [00:11\u003c00:06, 439.35it/s]",
            "\r 60%|█████▉    | 4363/7292 [00:11\u003c00:06, 445.35it/s]",
            "\r 60%|██████    | 4409/7292 [00:11\u003c00:06, 447.03it/s]",
            "\r 61%|██████    | 4455/7292 [00:11\u003c00:06, 449.54it/s]",
            "\r 62%|██████▏   | 4500/7292 [00:11\u003c00:06, 449.61it/s]",
            "\r 62%|██████▏   | 4545/7292 [00:11\u003c00:06, 444.42it/s]",
            "\r 63%|██████▎   | 4590/7292 [00:11\u003c00:06, 438.24it/s]",
            "\r 64%|██████▎   | 4638/7292 [00:11\u003c00:05, 447.47it/s]",
            "\r 64%|██████▍   | 4683/7292 [00:11\u003c00:06, 413.15it/s]",
            "\r 65%|██████▍   | 4726/7292 [00:12\u003c00:06, 416.84it/s]",
            "\r 65%|██████▌   | 4772/7292 [00:12\u003c00:05, 427.74it/s]",
            "\r 66%|██████▌   | 4819/7292 [00:12\u003c00:05, 439.56it/s]",
            "\r 67%|██████▋   | 4864/7292 [00:12\u003c00:05, 417.98it/s]",
            "\r 67%|██████▋   | 4907/7292 [00:12\u003c00:05, 411.85it/s]",
            "\r 68%|██████▊   | 4949/7292 [00:12\u003c00:05, 397.78it/s]",
            "\r 68%|██████▊   | 4993/7292 [00:12\u003c00:05, 408.41it/s]",
            "\r 69%|██████▉   | 5035/7292 [00:12\u003c00:05, 409.43it/s]",
            "\r 70%|██████▉   | 5081/7292 [00:12\u003c00:05, 422.23it/s]",
            "\r 70%|███████   | 5127/7292 [00:12\u003c00:05, 431.59it/s]",
            "\r 71%|███████   | 5173/7292 [00:13\u003c00:04, 439.71it/s]",
            "\r 72%|███████▏  | 5218/7292 [00:13\u003c00:04, 416.89it/s]",
            "\r 72%|███████▏  | 5263/7292 [00:13\u003c00:04, 425.08it/s]",
            "\r 73%|███████▎  | 5308/7292 [00:13\u003c00:04, 431.02it/s]",
            "\r 73%|███████▎  | 5353/7292 [00:13\u003c00:04, 435.28it/s]",
            "\r 74%|███████▍  | 5397/7292 [00:13\u003c00:04, 425.29it/s]",
            "\r 75%|███████▍  | 5443/7292 [00:13\u003c00:04, 432.68it/s]",
            "\r 75%|███████▌  | 5488/7292 [00:13\u003c00:04, 433.95it/s]",
            "\r 76%|███████▌  | 5532/7292 [00:13\u003c00:04, 434.42it/s]",
            "\r 76%|███████▋  | 5576/7292 [00:14\u003c00:04, 423.47it/s]",
            "\r 77%|███████▋  | 5621/7292 [00:14\u003c00:03, 429.87it/s]",
            "\r 78%|███████▊  | 5665/7292 [00:14\u003c00:03, 429.07it/s]",
            "\r 78%|███████▊  | 5710/7292 [00:14\u003c00:03, 435.12it/s]",
            "\r 79%|███████▉  | 5754/7292 [00:14\u003c00:03, 412.01it/s]",
            "\r 79%|███████▉  | 5797/7292 [00:14\u003c00:03, 416.06it/s]",
            "\r 80%|████████  | 5842/7292 [00:14\u003c00:03, 424.47it/s]",
            "\r 81%|████████  | 5887/7292 [00:14\u003c00:03, 430.53it/s]",
            "\r 81%|████████▏ | 5931/7292 [00:14\u003c00:03, 409.16it/s]",
            "\r 82%|████████▏ | 5978/7292 [00:14\u003c00:03, 424.54it/s]",
            "\r 83%|████████▎ | 6021/7292 [00:15\u003c00:03, 407.98it/s]",
            "\r 83%|████████▎ | 6066/7292 [00:15\u003c00:02, 417.41it/s]",
            "\r 84%|████████▍ | 6109/7292 [00:15\u003c00:02, 413.79it/s]",
            "\r 84%|████████▍ | 6155/7292 [00:15\u003c00:02, 419.65it/s]",
            "\r 85%|████████▍ | 6198/7292 [00:15\u003c00:02, 421.47it/s]",
            "\r 86%|████████▌ | 6244/7292 [00:15\u003c00:02, 432.31it/s]",
            "\r 86%|████████▋ | 6290/7292 [00:15\u003c00:02, 437.76it/s]",
            "\r 87%|████████▋ | 6334/7292 [00:15\u003c00:02, 423.24it/s]",
            "\r 87%|████████▋ | 6379/7292 [00:15\u003c00:02, 428.49it/s]",
            "\r 88%|████████▊ | 6423/7292 [00:16\u003c00:02, 424.35it/s]",
            "\r 89%|████████▊ | 6466/7292 [00:16\u003c00:01, 422.24it/s]",
            "\r 89%|████████▉ | 6509/7292 [00:16\u003c00:01, 414.74it/s]",
            "\r 90%|████████▉ | 6553/7292 [00:16\u003c00:01, 422.00it/s]",
            "\r 90%|█████████ | 6596/7292 [00:16\u003c00:01, 418.12it/s]",
            "\r 91%|█████████ | 6643/7292 [00:16\u003c00:01, 430.07it/s]",
            "\r 92%|█████████▏| 6687/7292 [00:16\u003c00:01, 403.26it/s]",
            "\r 92%|█████████▏| 6728/7292 [00:16\u003c00:01, 402.86it/s]",
            "\r 93%|█████████▎| 6775/7292 [00:16\u003c00:01, 418.66it/s]",
            "\r 94%|█████████▎| 6822/7292 [00:16\u003c00:01, 431.65it/s]",
            "\r 94%|█████████▍| 6866/7292 [00:17\u003c00:00, 431.54it/s]",
            "\r 95%|█████████▍| 6910/7292 [00:17\u003c00:00, 419.16it/s]",
            "\r 95%|█████████▌| 6955/7292 [00:17\u003c00:00, 424.35it/s]",
            "\r 96%|█████████▌| 6998/7292 [00:17\u003c00:00, 425.98it/s]",
            "\r 97%|█████████▋| 7043/7292 [00:17\u003c00:00, 431.69it/s]",
            "\r 97%|█████████▋| 7087/7292 [00:17\u003c00:00, 434.12it/s]",
            "\r 98%|█████████▊| 7131/7292 [00:17\u003c00:00, 357.29it/s]",
            "\r 98%|█████████▊| 7172/7292 [00:17\u003c00:00, 369.62it/s]",
            "\r 99%|█████████▉| 7214/7292 [00:17\u003c00:00, 382.34it/s]",
            "\r100%|█████████▉| 7261/7292 [00:18\u003c00:00, 403.93it/s]",
            "\r100%|██████████| 7292/7292 [00:18\u003c00:00, 400.90it/s]",
            "\n",
            "\r  0%|          | 0/7500 [00:00\u003c?, ?it/s]",
            "\r  0%|          | 26/7500 [00:00\u003c00:29, 257.43it/s]",
            "\r  1%|          | 72/7500 [00:00\u003c00:25, 296.01it/s]",
            "\r  2%|▏         | 117/7500 [00:00\u003c00:22, 328.39it/s]",
            "\r  2%|▏         | 162/7500 [00:00\u003c00:20, 356.50it/s]",
            "\r  3%|▎         | 203/7500 [00:00\u003c00:19, 371.02it/s]",
            "\r  3%|▎         | 250/7500 [00:00\u003c00:18, 394.06it/s]",
            "\r  4%|▍         | 295/7500 [00:00\u003c00:17, 406.01it/s]",
            "\r  5%|▍         | 343/7500 [00:00\u003c00:16, 424.54it/s]",
            "\r  5%|▌         | 391/7500 [00:00\u003c00:16, 436.18it/s]",
            "\r  6%|▌         | 435/7500 [00:01\u003c00:16, 423.44it/s]",
            "\r  6%|▋         | 480/7500 [00:01\u003c00:16, 429.86it/s]",
            "\r  7%|▋         | 525/7500 [00:01\u003c00:16, 434.44it/s]",
            "\r  8%|▊         | 569/7500 [00:01\u003c00:16, 430.93it/s]",
            "\r  8%|▊         | 613/7500 [00:01\u003c00:16, 416.40it/s]",
            "\r  9%|▉         | 658/7500 [00:01\u003c00:16, 423.53it/s]",
            "\r  9%|▉         | 704/7500 [00:01\u003c00:15, 433.84it/s]",
            "\r 10%|█         | 751/7500 [00:01\u003c00:15, 444.07it/s]",
            "\r 11%|█         | 796/7500 [00:01\u003c00:15, 419.67it/s]",
            "\r 11%|█         | 841/7500 [00:01\u003c00:15, 428.31it/s]",
            "\r 12%|█▏        | 889/7500 [00:02\u003c00:14, 441.37it/s]",
            "\r 12%|█▏        | 934/7500 [00:02\u003c00:14, 440.03it/s]",
            "\r 13%|█▎        | 979/7500 [00:02\u003c00:15, 429.02it/s]",
            "\r 14%|█▎        | 1024/7500 [00:02\u003c00:14, 432.60it/s]",
            "\r 14%|█▍        | 1069/7500 [00:02\u003c00:14, 436.42it/s]",
            "\r 15%|█▍        | 1115/7500 [00:02\u003c00:14, 439.43it/s]",
            "\r 15%|█▌        | 1161/7500 [00:02\u003c00:14, 444.12it/s]",
            "\r 16%|█▌        | 1206/7500 [00:02\u003c00:14, 431.72it/s]",
            "\r 17%|█▋        | 1252/7500 [00:02\u003c00:14, 437.32it/s]",
            "\r 17%|█▋        | 1297/7500 [00:03\u003c00:14, 438.48it/s]",
            "\r 18%|█▊        | 1344/7500 [00:03\u003c00:13, 444.96it/s]",
            "\r 19%|█▊        | 1389/7500 [00:03\u003c00:14, 432.29it/s]",
            "\r 19%|█▉        | 1436/7500 [00:03\u003c00:13, 440.48it/s]",
            "\r 20%|█▉        | 1481/7500 [00:03\u003c00:13, 443.27it/s]",
            "\r 20%|██        | 1526/7500 [00:03\u003c00:13, 445.25it/s]",
            "\r 21%|██        | 1571/7500 [00:03\u003c00:13, 433.74it/s]",
            "\r 22%|██▏       | 1618/7500 [00:03\u003c00:13, 441.54it/s]",
            "\r 22%|██▏       | 1663/7500 [00:03\u003c00:13, 440.14it/s]",
            "\r 23%|██▎       | 1708/7500 [00:03\u003c00:13, 440.44it/s]",
            "\r 23%|██▎       | 1753/7500 [00:04\u003c00:13, 438.09it/s]",
            "\r 24%|██▍       | 1799/7500 [00:04\u003c00:12, 443.16it/s]",
            "\r 25%|██▍       | 1844/7500 [00:04\u003c00:12, 445.17it/s]",
            "\r 25%|██▌       | 1891/7500 [00:04\u003c00:12, 451.03it/s]",
            "\r 26%|██▌       | 1937/7500 [00:04\u003c00:13, 415.58it/s]",
            "\r 26%|██▋       | 1983/7500 [00:04\u003c00:12, 427.97it/s]",
            "\r 27%|██▋       | 2027/7500 [00:04\u003c00:12, 428.99it/s]",
            "\r 28%|██▊       | 2071/7500 [00:04\u003c00:13, 408.17it/s]",
            "\r 28%|██▊       | 2117/7500 [00:04\u003c00:12, 420.14it/s]",
            "\r 29%|██▉       | 2164/7500 [00:04\u003c00:12, 432.77it/s]",
            "\r 29%|██▉       | 2211/7500 [00:05\u003c00:11, 443.30it/s]",
            "\r 30%|███       | 2256/7500 [00:05\u003c00:12, 409.91it/s]",
            "\r 31%|███       | 2302/7500 [00:05\u003c00:12, 421.45it/s]",
            "\r 31%|███▏      | 2345/7500 [00:05\u003c00:12, 418.40it/s]",
            "\r 32%|███▏      | 2388/7500 [00:05\u003c00:12, 419.35it/s]",
            "\r 32%|███▏      | 2431/7500 [00:05\u003c00:12, 410.38it/s]",
            "\r 33%|███▎      | 2478/7500 [00:05\u003c00:11, 423.15it/s]",
            "\r 34%|███▎      | 2523/7500 [00:05\u003c00:11, 430.81it/s]",
            "\r 34%|███▍      | 2571/7500 [00:05\u003c00:11, 442.04it/s]",
            "\r 35%|███▍      | 2616/7500 [00:06\u003c00:11, 429.14it/s]",
            "\r 35%|███▌      | 2660/7500 [00:06\u003c00:11, 432.32it/s]",
            "\r 36%|███▌      | 2708/7500 [00:06\u003c00:10, 444.36it/s]",
            "\r 37%|███▋      | 2753/7500 [00:06\u003c00:10, 440.77it/s]",
            "\r 37%|███▋      | 2798/7500 [00:06\u003c00:10, 428.26it/s]",
            "\r 38%|███▊      | 2843/7500 [00:06\u003c00:10, 432.05it/s]",
            "\r 39%|███▊      | 2889/7500 [00:06\u003c00:10, 440.07it/s]",
            "\r 39%|███▉      | 2934/7500 [00:06\u003c00:10, 430.28it/s]",
            "\r 40%|███▉      | 2979/7500 [00:06\u003c00:10, 433.50it/s]",
            "\r 40%|████      | 3024/7500 [00:06\u003c00:10, 438.32it/s]",
            "\r 41%|████      | 3070/7500 [00:07\u003c00:09, 443.33it/s]",
            "\r 42%|████▏     | 3115/7500 [00:07\u003c00:10, 428.74it/s]",
            "\r 42%|████▏     | 3159/7500 [00:07\u003c00:10, 424.57it/s]",
            "\r 43%|████▎     | 3204/7500 [00:07\u003c00:09, 430.60it/s]",
            "\r 43%|████▎     | 3251/7500 [00:07\u003c00:09, 440.46it/s]",
            "\r 44%|████▍     | 3296/7500 [00:07\u003c00:10, 416.24it/s]",
            "\r 45%|████▍     | 3340/7500 [00:07\u003c00:09, 423.08it/s]",
            "\r 45%|████▌     | 3385/7500 [00:07\u003c00:09, 429.56it/s]",
            "\r 46%|████▌     | 3429/7500 [00:07\u003c00:09, 428.85it/s]",
            "\r 46%|████▋     | 3474/7500 [00:08\u003c00:09, 434.87it/s]",
            "\r 47%|████▋     | 3520/7500 [00:08\u003c00:09, 439.59it/s]",
            "\r 48%|████▊     | 3568/7500 [00:08\u003c00:08, 447.22it/s]",
            "\r 48%|████▊     | 3615/7500 [00:08\u003c00:08, 452.48it/s]",
            "\r 49%|████▉     | 3662/7500 [00:08\u003c00:08, 454.94it/s]",
            "\r 49%|████▉     | 3710/7500 [00:08\u003c00:08, 459.52it/s]",
            "\r 50%|█████     | 3757/7500 [00:08\u003c00:08, 459.90it/s]",
            "\r 51%|█████     | 3804/7500 [00:08\u003c00:08, 458.82it/s]",
            "\r 51%|█████▏    | 3850/7500 [00:08\u003c00:07, 457.83it/s]",
            "\r 52%|█████▏    | 3896/7500 [00:08\u003c00:07, 458.40it/s]",
            "\r 53%|█████▎    | 3943/7500 [00:09\u003c00:07, 461.76it/s]",
            "\r 53%|█████▎    | 3990/7500 [00:09\u003c00:07, 452.17it/s]",
            "\r 54%|█████▍    | 4036/7500 [00:09\u003c00:07, 443.94it/s]",
            "\r 54%|█████▍    | 4081/7500 [00:09\u003c00:07, 444.42it/s]",
            "\r 55%|█████▌    | 4127/7500 [00:09\u003c00:07, 446.39it/s]",
            "\r 56%|█████▌    | 4172/7500 [00:09\u003c00:07, 447.44it/s]",
            "\r 56%|█████▌    | 4217/7500 [00:09\u003c00:07, 442.93it/s]",
            "\r 57%|█████▋    | 4262/7500 [00:09\u003c00:07, 442.41it/s]",
            "\r 57%|█████▋    | 4307/7500 [00:09\u003c00:07, 439.45it/s]",
            "\r 58%|█████▊    | 4355/7500 [00:09\u003c00:07, 448.35it/s]",
            "\r 59%|█████▊    | 4402/7500 [00:10\u003c00:06, 453.31it/s]",
            "\r 59%|█████▉    | 4448/7500 [00:10\u003c00:06, 451.16it/s]",
            "\r 60%|█████▉    | 4495/7500 [00:10\u003c00:06, 452.72it/s]",
            "\r 61%|██████    | 4541/7500 [00:10\u003c00:06, 437.96it/s]",
            "\r 61%|██████    | 4585/7500 [00:10\u003c00:06, 434.67it/s]",
            "\r 62%|██████▏   | 4632/7500 [00:10\u003c00:06, 443.44it/s]",
            "\r 62%|██████▏   | 4679/7500 [00:10\u003c00:06, 451.09it/s]",
            "\r 63%|██████▎   | 4725/7500 [00:10\u003c00:06, 429.57it/s]",
            "\r 64%|██████▎   | 4769/7500 [00:10\u003c00:06, 428.86it/s]",
            "\r 64%|██████▍   | 4815/7500 [00:11\u003c00:06, 435.28it/s]",
            "\r 65%|██████▍   | 4860/7500 [00:11\u003c00:06, 437.04it/s]",
            "\r 65%|██████▌   | 4904/7500 [00:11\u003c00:05, 435.31it/s]",
            "\r 66%|██████▌   | 4948/7500 [00:11\u003c00:05, 436.70it/s]",
            "\r 67%|██████▋   | 4993/7500 [00:11\u003c00:05, 438.05it/s]",
            "\r 67%|██████▋   | 5039/7500 [00:11\u003c00:05, 444.39it/s]",
            "\r 68%|██████▊   | 5084/7500 [00:11\u003c00:05, 431.93it/s]",
            "\r 68%|██████▊   | 5128/7500 [00:11\u003c00:05, 433.05it/s]",
            "\r 69%|██████▉   | 5175/7500 [00:11\u003c00:05, 443.46it/s]",
            "\r 70%|██████▉   | 5220/7500 [00:11\u003c00:05, 443.99it/s]",
            "\r 70%|███████   | 5265/7500 [00:12\u003c00:06, 361.00it/s]",
            "\r 71%|███████   | 5306/7500 [00:12\u003c00:05, 374.39it/s]",
            "\r 71%|███████▏  | 5353/7500 [00:12\u003c00:05, 396.72it/s]",
            "\r 72%|███████▏  | 5397/7500 [00:12\u003c00:05, 406.54it/s]",
            "\r 73%|███████▎  | 5439/7500 [00:12\u003c00:05, 385.62it/s]",
            "\r 73%|███████▎  | 5485/7500 [00:12\u003c00:04, 404.20it/s]",
            "\r 74%|███████▎  | 5527/7500 [00:12\u003c00:04, 396.09it/s]",
            "\r 74%|███████▍  | 5568/7500 [00:12\u003c00:04, 396.68it/s]",
            "\r 75%|███████▍  | 5609/7500 [00:12\u003c00:04, 393.65it/s]",
            "\r 75%|███████▌  | 5655/7500 [00:13\u003c00:04, 410.34it/s]",
            "\r 76%|███████▌  | 5700/7500 [00:13\u003c00:04, 420.24it/s]",
            "\r 77%|███████▋  | 5743/7500 [00:13\u003c00:04, 415.76it/s]",
            "\r 77%|███████▋  | 5789/7500 [00:13\u003c00:04, 425.73it/s]",
            "\r 78%|███████▊  | 5835/7500 [00:13\u003c00:03, 434.23it/s]",
            "\r 78%|███████▊  | 5881/7500 [00:13\u003c00:03, 441.64it/s]",
            "\r 79%|███████▉  | 5927/7500 [00:13\u003c00:03, 445.72it/s]",
            "\r 80%|███████▉  | 5972/7500 [00:13\u003c00:03, 430.32it/s]",
            "\r 80%|████████  | 6016/7500 [00:13\u003c00:03, 429.38it/s]",
            "\r 81%|████████  | 6061/7500 [00:14\u003c00:03, 432.85it/s]",
            "\r 81%|████████▏ | 6105/7500 [00:14\u003c00:03, 427.34it/s]",
            "\r 82%|████████▏ | 6148/7500 [00:14\u003c00:03, 408.63it/s]",
            "\r 83%|████████▎ | 6192/7500 [00:14\u003c00:03, 415.19it/s]",
            "\r 83%|████████▎ | 6236/7500 [00:14\u003c00:02, 422.31it/s]",
            "\r 84%|████████▍ | 6282/7500 [00:14\u003c00:02, 431.71it/s]",
            "\r 84%|████████▍ | 6329/7500 [00:14\u003c00:02, 441.23it/s]",
            "\r 85%|████████▍ | 6374/7500 [00:14\u003c00:02, 431.07it/s]",
            "\r 86%|████████▌ | 6418/7500 [00:14\u003c00:02, 428.63it/s]",
            "\r 86%|████████▌ | 6465/7500 [00:14\u003c00:02, 437.81it/s]",
            "\r 87%|████████▋ | 6509/7500 [00:15\u003c00:02, 437.14it/s]",
            "\r 87%|████████▋ | 6553/7500 [00:15\u003c00:02, 436.71it/s]",
            "\r 88%|████████▊ | 6597/7500 [00:15\u003c00:02, 435.06it/s]",
            "\r 89%|████████▊ | 6642/7500 [00:15\u003c00:01, 439.41it/s]",
            "\r 89%|████████▉ | 6688/7500 [00:15\u003c00:01, 444.13it/s]",
            "\r 90%|████████▉ | 6734/7500 [00:15\u003c00:01, 447.44it/s]",
            "\r 90%|█████████ | 6779/7500 [00:15\u003c00:01, 388.95it/s]",
            "\r 91%|█████████ | 6824/7500 [00:15\u003c00:01, 404.34it/s]",
            "\r 92%|█████████▏| 6871/7500 [00:15\u003c00:01, 420.92it/s]",
            "\r 92%|█████████▏| 6916/7500 [00:16\u003c00:01, 426.79it/s]",
            "\r 93%|█████████▎| 6960/7500 [00:16\u003c00:01, 417.99it/s]",
            "\r 93%|█████████▎| 7008/7500 [00:16\u003c00:01, 432.49it/s]",
            "\r 94%|█████████▍| 7052/7500 [00:16\u003c00:01, 430.90it/s]",
            "\r 95%|█████████▍| 7096/7500 [00:16\u003c00:00, 428.49it/s]",
            "\r 95%|█████████▌| 7144/7500 [00:16\u003c00:00, 442.73it/s]",
            "\r 96%|█████████▌| 7189/7500 [00:16\u003c00:00, 432.09it/s]",
            "\r 96%|█████████▋| 7233/7500 [00:16\u003c00:00, 428.10it/s]",
            "\r 97%|█████████▋| 7281/7500 [00:16\u003c00:00, 439.99it/s]",
            "\r 98%|█████████▊| 7327/7500 [00:16\u003c00:00, 443.23it/s]",
            "\r 98%|█████████▊| 7372/7500 [00:17\u003c00:00, 443.95it/s]",
            "\r 99%|█████████▉| 7417/7500 [00:17\u003c00:00, 444.40it/s]",
            "\r 99%|█████████▉| 7462/7500 [00:17\u003c00:00, 427.04it/s]",
            "\r100%|██████████| 7500/7500 [00:17\u003c00:00, 431.98it/s]",
            "\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": [
            "Model(\n  (features): Sequential(\n    (0): Conv2d(1, 64, kernel_size\u003d(3, 3), stride\u003d(1, 1), padding\u003d(1, 1))\n    (1): BatchNorm2d(64, eps\u003d1e-05, momentum\u003d0.1, affine\u003dTrue, track_running_stats\u003dTrue)\n    (2): ReLU(inplace\u003dTrue)\n    (3): Conv2d(64, 128, kernel_size\u003d(3, 3), stride\u003d(1, 1), padding\u003d(1, 1))\n    (4): BatchNorm2d(128, eps\u003d1e-05, momentum\u003d0.1, affine\u003dTrue, track_running_stats\u003dTrue)\n    (5): ReLU(inplace\u003dTrue)\n    (6): MaxPool2d(kernel_size\u003d2, stride\u003d2, padding\u003d0, dilation\u003d1, ceil_mode\u003dFalse)\n    (7): Conv2d(128, 256, kernel_size\u003d(3, 3), stride\u003d(1, 1), padding\u003d(1, 1))\n    (8): BatchNorm2d(256, eps\u003d1e-05, momentum\u003d0.1, affine\u003dTrue, track_running_stats\u003dTrue)\n    (9): ReLU(inplace\u003dTrue)\n    (10): Conv2d(256, 256, kernel_size\u003d(3, 3), stride\u003d(1, 1), padding\u003d(1, 1))\n    (11): BatchNorm2d(256, eps\u003d1e-05, momentum\u003d0.1, affine\u003dTrue, track_running_stats\u003dTrue)\n    (12): ReLU(inplace\u003dTrue)\n    (13): AdaptiveMaxPool2d(output_size\u003d(1, 1))\n    (14): Dropout(p\u003d0.3, inplace\u003dFalse)\n  )\n  (classier): Linear(in_features\u003d256, out_features\u003d19, bias\u003dTrue)\n)\nepoch:0-lr:0.00100000-----\n"
          ],
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-16-ba0eaab5cec3\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                             \u001b[0mreduceLR\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mreduceLR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 67\u001b[1;33m                             earlyStopping\u003dearlyStopping)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_best_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-10-06fb99668446\u003e\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, dataloader, epochs, validation_data, reduceLR, earlyStopping, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 39\u001b[1;33m             \u001b[0mresult_epoch\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_on_a_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;31m# log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-10-06fb99668446\u003e\u001b[0m in \u001b[0;36miter_on_a_epoch\u001b[1;34m(self, phase, dataloader, loss_dict, metric, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;31m# for cnt_batch, batch in zip(tqdm(range(1, len(dataloader) + 1)), dataloader):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcnt_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 81\u001b[1;33m             \u001b[0mresult_batch\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_on_a_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;31m#返回结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mscore_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[0mresult_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"score_batch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label_batch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"img_batch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-10-06fb99668446\u003e\u001b[0m in \u001b[0;36miter_on_a_batch\u001b[1;34m(self, batch, phase, loss_dict)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mlabel_tensor\u001b[0m \u001b[1;33m\u003d\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_tran\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 124\u001b[1;33m         \u001b[0mscore_tensor\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[1;31m# update_mask_batch\u003dmask_tensor.detach().cpu().numpy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m###### cul loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m                 raise RuntimeError(\"module must have its parameters and buffers \"\n\u001b[0;32m    148\u001b[0m                                    \u001b[1;34m\"on device {} (device_ids[0]) but found one of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--\u003e 149\u001b[1;33m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu"
          ],
          "ename": "RuntimeError",
          "evalue": "module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu",
          "output_type": "error"
        }
      ],
      "source": "import random\nrandom.seed(1)\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nimport os\nimport time\nfrom torch.optim import SGD, lr_scheduler, Adam\n\ntimer \u003d time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\nSAVE_DIR\u003d\"./save_{}/\".format(timer)\nif not os.path.exists(SAVE_DIR):\n    os.makedirs(SAVE_DIR)\n\ndata_dir\u003d\"./data\"\nsub\u003dpd.read_csv(\"./data/submit.csv\")\nEPOCH\u003d150\nBATCH_SIZE\u003d512\n\nDEVICE_INFO\u003ddict(\n    gpu_num\u003dtorch.cuda.device_count(),\n    device_ids \u003d range(0, torch.cuda.device_count(), 1),\n    #device \u003d \"cpu\",\n    device \u003d torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\",\n    index_cuda\u003d0, )\n\nNUM_CLASSES \u003d 19\n\nACTIVATION\u003d\"relu\"\n\nMETRICS\u003dXWMetrics()\ntrain_data\u003dXWDataset(os.path.join(data_dir,\"sensor_train.csv\"),with_label\u003dTrue)\ntest_data\u003dXWDataset(os.path.join(data_dir,\"sensor_test.csv\"),with_label\u003dFalse,)\nproba_t \u003d np.zeros((len(test_data), NUM_CLASSES))\nfolds\u003d5\ntrain_data.stratifiedKFold(folds)\nfor fold in range(folds):\n\t#定义模型\n    #划分训练集和验证集 并返回验证集数据\n    model\u003dModel(num_classes\u003dNUM_CLASSES)\n    save_dir\u003dos.path.join(SAVE_DIR,\"flod_{}\".format(fold))\n    agent\u003dAgent(model\u003dmodel,device_info\u003dDEVICE_INFO, save_dir\u003dsave_dir)\n    earlyStopping \u003d None\n\t\n\t#定义损失\n    LOSS\u003d{ \"celoss\":CELoss() }\n\t\n\t#定义优化器\n    OPTIM\u003dAdam(model.parameters(), lr\u003d0.001, weight_decay\u003d0.001)\n\t\n\t#定义损失\n    reduceLR \u003d lr_scheduler.ReduceLROnPlateau(OPTIM, mode\u003d\"max\", factor\u003d0.5, patience\u003d8, verbose\u003dTrue)\n\t\n    agent.compile(loss_dict\u003dLOSS,optimizer\u003dOPTIM, metrics\u003dMETRICS)\n    agent.summary()\n\t\n\t#生成验证集\n    valid_X,valid_Y\u003dtrain_data.get_valid_data(fold)\n    valid_Y\u003done_hot(valid_Y,NUM_CLASSES)\n    valid_data \u003d [(valid_X[i],valid_Y[i]) for i in range(valid_X.shape[0])]\n\n    train_generator\u003dDataLoader(train_data,batch_size\u003dBATCH_SIZE,shuffle\u003dTrue,num_workers\u003d0)\n\t#生成验证集\n    agent.fit_generator(train_generator, epochs\u003dEPOCH,\n                                  validation_data\u003dvalid_data,\n                            reduceLR\u003dreduceLR,\n                            earlyStopping\u003dearlyStopping)\n\n    agent.load_best_model()\n    test_X\u003d[test_data.data[i] for i in range(test_data.data.shape[0])]\n    scores_test\u003d agent.predict(test_X,batch_size\u003d1024,phase\u003d\"test\")\n    proba_t+\u003dscores_test/5.\nsub.behavior_id \u003d np.argmax(proba_t, axis\u003d1)\nsub.to_csv(SAVE_DIR+\u0027submit.csv\u0027, index\u003dFalse)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}